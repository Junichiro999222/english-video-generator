{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ea708-fbb4-4841-9889-f54c07f8444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def find_zombie_processes():\n",
    "    \"\"\"Find all zombie processes.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run([\"ps\", \"aux\"], capture_output=True, text=True)\n",
    "        lines = result.stdout.split(\"\\n\")\n",
    "\n",
    "        zombie_pids = []\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) > 7 and parts[7] == \"Z\":\n",
    "                pid = parts[1]  # PID is the second column\n",
    "                zombie_pids.append(pid)\n",
    "\n",
    "        return zombie_pids\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding zombie processes: {e}\")\n",
    "        return []\n",
    "\n",
    "def kill_processes(pids):\n",
    "    \"\"\"Kill processes by PID.\"\"\"\n",
    "    for pid in pids:\n",
    "        try:\n",
    "            subprocess.run([\"sudo\", \"kill\", \"-9\", pid], check=True)\n",
    "            print(f\"âœ… Killed zombie process: {pid}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to kill process {pid}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    zombie_pids = find_zombie_processes()\n",
    "    if zombie_pids:\n",
    "        print(f\"ğŸ§Ÿ Found zombie processes: {zombie_pids}\")\n",
    "        kill_processes(zombie_pids)\n",
    "    else:\n",
    "        print(\"ğŸ‰ No zombie processes found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73f2722-3011-4a74-a516-8124b40c27bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d304ba9d-9318-4f35-8fda-64b154f84c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e330266-cf91-41e0-a479-407fe91cc9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import openai\n",
    "import json\n",
    "import csv\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# method = \"songs\"\n",
    "method = \"artists\"\n",
    "\n",
    "if method == \"songs\":\n",
    "    all_songs = {\n",
    "            \"Alan Walker\": [\"Faded\"],\n",
    "        }\n",
    "    artists= list(all_songs.keys())\n",
    "    def get_top_songs(artist):\n",
    "        return all_songs.get(artist, [])[:1]\n",
    "\n",
    "elif method == \"artists\":\n",
    "    # === Step 1: Define artist list ===\n",
    "    artists = [ \"Queen\",\"Bruno Mars\", \"Lady Gaga\",\"EMINEM\",\"Green day\", \"Yes\",\n",
    "           \t\"The rolling stones\",\"Red zeppelin\",\"The stone roses\", \"The Beatles\",\"Oasis\",\n",
    "           \t\"Backstreet boys\", \"Bon Jovi\",\"David Bowie\", \"Alan Walker\", \"Elton Jon\",\n",
    "           \t\"Sting\",\"Billy Joel\",\"Ed Sheeran\", \"Twenty One Pilots\"]\n",
    "    # artists = [\"Red zeppelin\"]\n",
    "    \n",
    "    # === Step 2: Function to get top 5 songs using ChatGPT API ===\n",
    "    def get_top_songs(artist: str) -> List[str]:\n",
    "    \tclient = openai.OpenAI(api_key=\"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\")  # APIã‚­ãƒ¼ã‚’ã‚»ãƒƒãƒˆ\n",
    "    \tresponse = client.chat.completions.create(\n",
    "    \tmodel=\"gpt-4\",\n",
    "    \tmessages=[\n",
    "        \t{\"role\": \"system\", \"content\": \"You are a my assistant.\"},\n",
    "        \t{\"role\": \"user\", \"content\": f\"List 3 of the most famous songs by {artist}. Only return a plain numbered list of song titles, no extra explanation.\"}\n",
    "    \t]\n",
    "    \t)\n",
    "    \ttext = response.choices[0].message.content\n",
    "    \tprint(text)\n",
    "    \tsongs = [line.split(\". \", 1)[-1].strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "    \treturn songs[:3]\n",
    "\n",
    "\n",
    "\n",
    "# === Step 3: Utility to check audio file ===\n",
    "def file_found(path: Path, exts=[\".mp3\", \".m4a\"]) -> bool:\n",
    "    return any((path / f\"music{ext}\").exists() for ext in exts)\n",
    "\n",
    "# === Step 4: Extract reference URL ===\n",
    "def extract_reference_url(path: Path) -> str:\n",
    "    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã® info.json ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å…¨éƒ¨è¦‹ã‚‹\n",
    "    for file in path.glob(\"music.*.info.json\"):\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                url = data.get(\"webpage_url\", \"\")\n",
    "                if url.startswith(\"http\"):\n",
    "                    return url  # æœ€åˆã«è¦‹ã¤ã‘ãŸæœ¬ç‰©ã®URLã‚’è¿”ã™\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to read {file.name}: {e}\")\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "# === Step 5: Download audio ===\n",
    "def download_mp3(search_query: str, target_path: str):\n",
    "    os.makedirs(target_path, exist_ok=True)\n",
    "    path = Path(target_path)\n",
    "\n",
    "    for n in [1, 3, 5, 7]:\n",
    "        print(f\"ğŸ” Trying: scsearch{n}:{search_query}\")\n",
    "        command = [\n",
    "            \"yt-dlp\",\n",
    "            f\"scsearch{n}:{search_query} full\",\n",
    "            \"-x\", \"--audio-format\", \"mp3\",\n",
    "            \"--write-info-json\",\n",
    "            \"-o\", os.path.join(target_path, \"music.%(id)s.%(ext)s\")\n",
    "        ]\n",
    "        subprocess.run(command, check=False)\n",
    "\n",
    "        # ğŸ”½ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸ mp3 ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™\n",
    "        mp3_files = list(path.glob(\"music.*.mp3\"))\n",
    "        if mp3_files:\n",
    "            downloaded_file = mp3_files[0]\n",
    "            final_path = path / \"music.mp3\"\n",
    "            downloaded_file.rename(final_path)  # ğŸ” music.mp3 ã«ãƒªãƒãƒ¼ãƒ \n",
    "            print(f\"âœ… Success with scsearch{n} - Saved as {final_path}\")\n",
    "            return\n",
    "\n",
    "        print(f\"âš ï¸ No valid audio file found with scsearch{n}, retrying...\")\n",
    "\n",
    "    print(f\"âŒ Failed to get good audio for: {search_query}\")\n",
    "\n",
    "# === Step 6: Copy notebook template ===\n",
    "def copy_notebook_template(target_path: str, notebook_template_path: str):\n",
    "    shutil.copy(os.path.join(notebook_template_path, \"../notebooks/Video_generate.ipynb\"), os.path.join(target_path, \"Video_generate.ipynb\"))\n",
    "\n",
    "# === Step 7: Create info.csv and templates ===\n",
    "def generate_info_csv(dataset_dir: str, artist: str, song: str, output_csv: str):\n",
    "    reference = extract_reference_url(Path(dataset_dir))\n",
    "    print(\"reference\", reference)\n",
    "    entry = {\"artist\": artist, \"song\": song, \"reference\": reference}\n",
    "    with open(output_csv, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"artist\", \"song\", \"reference\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerow(entry)\n",
    "\n",
    "def fill_templates(info_csv: str, base_dir: str,song_dir: str):\n",
    "    title_template_path=os.path.join(base_dir, \"../src/templates/title.txt\")\n",
    "    desc_template_path=os.path.join(base_dir, \"../src/templates/description.txt\")\n",
    "    title_tpl = Path(title_template_path).read_text(encoding=\"utf-8\")\n",
    "    desc_tpl = Path(desc_template_path).read_text(encoding=\"utf-8\")\n",
    "    with open(info_csv, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            title = title_tpl.format(artist=row[\"artist\"], music=row[\"song\"], reference=row[\"reference\"])\n",
    "            desc = desc_tpl.format(artist=row[\"artist\"], music=row[\"song\"], reference=row[\"reference\"])\n",
    "\n",
    "            Path(song_dir, \"title.txt\").write_text(title, encoding=\"utf-8\")\n",
    "            Path(song_dir, \"description.txt\").write_text(desc, encoding=\"utf-8\")\n",
    "\n",
    "# === Step 8: å…¨ä½“ã®çµ±åˆå‡¦ç† ===\n",
    "def generate_dataset_structure(base_dir: str, artists: List[str]):\n",
    "    for x, artist in enumerate(artists):\n",
    "        try:\n",
    "            top_songs = get_top_songs(artist)\n",
    "            for song in top_songs:\n",
    "                song_dir = os.path.join(base_dir, f\"{artist.replace(' ', '_')}_{song.replace(' ', '_')}\")\n",
    "                os.makedirs(song_dir, exist_ok=True)\n",
    "                download_mp3(f\"{artist} {song}\", song_dir)\n",
    "                copy_notebook_template(song_dir, base_dir)\n",
    "                info_csv = os.path.join(song_dir, \"info.csv\")\n",
    "                generate_info_csv(song_dir, artist, song, info_csv)\n",
    "                fill_templates(info_csv, base_dir,song_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {artist}: {e}\")\n",
    "            \n",
    "\n",
    "# Output path\n",
    "# Get current directory\n",
    "current_dir = os.getcwd()\n",
    "# Set output path relative to current directory\n",
    "output_base_dir = os.path.join(current_dir, \"songs_dataset\")\n",
    "# Now use output_base_dir as your base folder\n",
    "os.makedirs(output_base_dir, exist_ok=True)  # Create if doesn't exist\n",
    "\n",
    "\n",
    "# Uncomment to run the scaffolding\n",
    "generate_dataset_structure(output_base_dir, artists)\n",
    "\n",
    "\n",
    "# Notes:\n",
    "# - You should have `yt-dlp` installed and in PATH\n",
    "# - Replace \"YOUR_API_KEY\" with your actual OpenAI API key\n",
    "# - Place \"Music.ipynb\" in the same directory as this script\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f4402-81bd-48a0-8f0b-60023215f02f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "import time\n",
    "import multiprocessing\n",
    "import os\n",
    "import subprocess\n",
    "import papermill as pm\n",
    "\n",
    "\n",
    "def run_notebook_in_dir(index,dir_path):\n",
    "    delay_seconds = index * 65\n",
    "    \n",
    "    input_nb = dir_path / \"Video_generate.ipynb\"\n",
    "    output_nb = dir_path / \"Video_generate_output.ipynb\"\n",
    "    final_video = dir_path / \"final_video.mp4\"\n",
    "    pid = multiprocessing.current_process().pid\n",
    "\n",
    "    # print(f\"ğŸ“¦ PID {pid} â€” Preparing: {dir_path} (wait {delay_seconds}s)\", flush=True)\n",
    "    # time.sleep(delay_seconds)\n",
    "    # print(f\"â±ï¸ PID {pid} â€” Starting execution after delay: {dir_path}\", flush=True)\n",
    "\n",
    "    if input_nb.exists():\n",
    "        try:\n",
    "            # pm.execute_notebook(\n",
    "            #     str(input_nb),\n",
    "            #     str(output_nb),\n",
    "            #     parameters={},\n",
    "            #     kernel_name=\"python3\",\n",
    "            #     cwd=str(dir_path)  # â† ã‚³ã‚³ã§ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæŒ‡å®šã§ãã‚‹ï¼\n",
    "            # )\n",
    "            cmd = [\n",
    "                \"papermill\",\n",
    "                str(input_nb),\n",
    "                str(output_nb),\n",
    "                \"--kernel\", \"python3\",\n",
    "                \"--cwd\", str(dir_path)\n",
    "            ]\n",
    "            subprocess.run(cmd, check=True)\n",
    "\n",
    "            print(f\"âœ… PID {pid} â€” Done: {input_nb}\", flush=True)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ PID {pid} â€” Failed: {input_nb} -> {e}\", flush=True)\n",
    "            errored_file.write_text(str(e))\n",
    "    else:\n",
    "        print(f\"âš ï¸ PID {pid} â€” Notebook not found: {dir_path}\", flush=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ Starting run_all.py\")  # â† ã“ã‚Œã§æœ€åˆã«å‡ºåŠ›ã•ã‚Œã‚‹ã‹ç¢ºèªï¼\n",
    "    base_dir = Path(\"songs_dataset\")\n",
    "    print(\"ğŸ“‚ Collecting notebook directories...\", flush=True)\n",
    "    notebook_dirs = [p for p in base_dir.iterdir() if p.is_dir()]\n",
    "    print(f\"ğŸ“ Found {len(notebook_dirs)} candidate dirs\", flush=True)\n",
    "\n",
    "    # Skip dirs with existing final_video.mp4\n",
    "    filtered_dirs = []\n",
    "    for p in notebook_dirs:\n",
    "        print(\"directory:\",p)\n",
    "        final_video = p / \"final_video.mp4\"\n",
    "        first_music = p / \"music.mp3\"\n",
    "        errored_file = p / \"errored.txt\"\n",
    "        if final_video.exists():\n",
    "            print(f\"âœ… Skipping {p} (final_video.mp4 exists)\", flush=True)\n",
    "        else:\n",
    "            print(f\"ğŸš€ final_video_doesn't exist: {p}\", flush=True)\n",
    "            \n",
    "            if errored_file.exists():\n",
    "                print(f\"âŒ Skipping {p} (errored.txt exists)\", flush=True)\n",
    "            else:\n",
    "                print(f\"ğŸš€ errored.txt doesn't exist: {p}\", flush=True)\n",
    "\n",
    "                if first_music.exists():\n",
    "                    print(f\"ğŸš€ Queued for execution: {p}\", flush=True)\n",
    "                    filtered_dirs.append(p)\n",
    "                else:\n",
    "                    print(f\"âœ… Skipping {p} (first_music.mp3 doesn't exists)\", flush=True)\n",
    "\n",
    "    \n",
    "    notebook_dirs = filtered_dirs\n",
    "\n",
    "    # ğŸ”¥ å®Ÿè¡Œé–‹å§‹ï¼ˆåŒæ™‚ã«2å€‹ã¾ã§ï¼‰\n",
    "    max_workers = 1\n",
    "    running_processes = []\n",
    "\n",
    "    for index, dir_path in enumerate(filtered_dirs):\n",
    "        while len(running_processes) >= max_workers:\n",
    "            # ãƒ—ãƒ­ã‚»ã‚¹ãŒçµ‚ã‚ã‚‹ã®ã‚’å¾…ã¤\n",
    "            for proc in running_processes:\n",
    "                if not proc.is_alive():\n",
    "                    running_processes.remove(proc)\n",
    "            # time.sleep(65)\n",
    "\n",
    "        proc = multiprocessing.Process(target=run_notebook_in_dir, args=(index, dir_path))\n",
    "        proc.start()\n",
    "        running_processes.append(proc)\n",
    "\n",
    "    # æœ€å¾Œã®æ®‹ã‚Šã‚’å¾…ã¤\n",
    "    for proc in running_processes:\n",
    "        proc.join()\n",
    "\n",
    "    print(\"ğŸ‰ All notebooks done!!\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c57cfb-f034-4744-a451-5fdea831af76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaFileUpload\n",
    "import pickle\n",
    "from google.auth.transport.requests import Request\n",
    "import time\n",
    "\n",
    "def authenticate_youtube():\n",
    "    scopes = [\n",
    "        \"https://www.googleapis.com/auth/youtube.upload\",\n",
    "        \"https://www.googleapis.com/auth/youtube\"\n",
    "    ]\n",
    "    creds = None\n",
    "    token_path = \"token.pickle\"\n",
    "\n",
    "    # ğŸ”„ ãƒˆãƒ¼ã‚¯ãƒ³ã®èª­ã¿è¾¼ã¿\n",
    "    if os.path.exists(token_path):\n",
    "        with open(token_path, \"rb\") as token:\n",
    "            creds = pickle.load(token)\n",
    "\n",
    "    # ğŸ” ãƒˆãƒ¼ã‚¯ãƒ³ãŒæœŸé™åˆ‡ã‚Œãªã‚‰ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())  # â† ã“ã‚Œã§æ›´æ–°ã§ãã‚‹ï¼ï¼\n",
    "\n",
    "    # ğŸ†• ãªã‘ã‚Œã°æ–°è¦èªè¨¼\n",
    "    if not creds or not creds.valid:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file(\"client_secrets.json\", scopes)\n",
    "        for port in [8080, 8081, 8082, 8888]:\n",
    "            try:\n",
    "                creds = flow.run_local_server(port=port, open_browser=False)\n",
    "                break\n",
    "            except OSError:\n",
    "                print(f\"âš ï¸ Port {port} already in use, trying next...\")\n",
    "        else:\n",
    "            raise RuntimeError(\"ğŸ˜¢ No available ports for OAuth redirect.\")\n",
    "\n",
    "    # ğŸ’¾ ä¿å­˜\n",
    "    with open(token_path, \"wb\") as token:\n",
    "        pickle.dump(creds, token)\n",
    "\n",
    "    youtube = build(\"youtube\", \"v3\", credentials=creds)\n",
    "    return youtube\n",
    "\n",
    "\n",
    "def upload_video(youtube, video_path, title, description, category_id=\"22\", privacy_status=\"unlisted\"):\n",
    "    body = {\n",
    "        \"snippet\": {\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"categoryId\": category_id\n",
    "        },\n",
    "        \"status\": {\n",
    "            \"privacyStatus\": privacy_status\n",
    "        }\n",
    "    }\n",
    "    media = MediaFileUpload(video_path, chunksize=-1, resumable=True, mimetype=\"video/*\")\n",
    "    request = youtube.videos().insert(part=\"snippet,status\", body=body, media_body=media)\n",
    "    response = request.execute()\n",
    "    return response[\"id\"]\n",
    "\n",
    "def mark_as_uploaded(path):\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(\"uploaded\\n\")\n",
    "\n",
    "def load_text_file(path):\n",
    "    if not os.path.exists(path):\n",
    "        return \"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read().strip()\n",
    "\n",
    "def add_to_playlist(youtube, video_id, playlist_id):\n",
    "    request = youtube.playlistItems().insert(\n",
    "        part=\"snippet\",\n",
    "        body={\n",
    "            \"snippet\": {\n",
    "                \"playlistId\": playlist_id,\n",
    "                \"resourceId\": {\n",
    "                    \"kind\": \"youtube#video\",\n",
    "                    \"videoId\": video_id\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    response = request.execute()\n",
    "    return response\n",
    "\n",
    "def process_all_videos(base_dir=\"songs_dataset\"):\n",
    "    youtube = authenticate_youtube()\n",
    "    for dir_name in os.listdir(base_dir):\n",
    "        subdir = os.path.join(base_dir, dir_name)\n",
    "        if not os.path.isdir(subdir):\n",
    "            continue\n",
    "\n",
    "        uploaded_path = os.path.join(subdir, \"uploaded.txt\")\n",
    "        if os.path.exists(uploaded_path):\n",
    "            print(f\"âœ… Skipping {subdir}, already uploaded.\")\n",
    "            continue\n",
    "\n",
    "        video_path = os.path.join(subdir, \"final_video.mp4\")\n",
    "        title_path = os.path.join(subdir, \"title.txt\")\n",
    "        description_path = os.path.join(subdir, \"description.txt\")\n",
    "\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"âš ï¸ No video found in {subdir}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        title = load_text_file(title_path)\n",
    "        description = load_text_file(description_path)\n",
    "\n",
    "        print(f\"ğŸ”¼ Uploading video from: {subdir}\")\n",
    "\n",
    "        video_id = upload_video(youtube, os.path.join(subdir, \"final_video.mp4\"), title, description)\n",
    "        add_to_playlist(youtube, video_id, \"PLQ_36MSwXUhoOhtsRYX8zEpnzoMKaEkTT\")\n",
    "\n",
    "        video_id = upload_video(youtube, os.path.join(subdir, \"final_output.mp3\"), title, description)\n",
    "        add_to_playlist(youtube, video_id, \"PLQ_36MSwXUhoU1VbOFnRPxj30e2cAyTZ0\")\n",
    "        mark_as_uploaded(uploaded_path)  # âœ… æˆåŠŸæ™‚ã«ãƒãƒ¼ã‚¯ï¼\n",
    "        print(f\"ğŸ… Video uploaded!! : {subdir}\")\n",
    "        print(f\"âŒ› Waiting for next upload...\")\n",
    "        time.sleep(300)  # â† 5åˆ†ä¼‘æ†©ï¼ˆçŠ¶æ³ã«å¿œã˜ã¦èª¿æ•´ï¼‰\n",
    "\n",
    "# å®Ÿè¡Œ\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_videos(\"songs_dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a1cbb-c764-491f-a11f-80786fd733de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path(\"songs_dataset\")\n",
    "notebook_dirs = [p for p in base_dir.iterdir() if p.is_dir()]\n",
    "print(f\"ğŸ“ Found {len(notebook_dirs)} candidate dirs\", flush=True)\n",
    "\n",
    "# Skip dirs with existing final_video.mp4\n",
    "filtered_dirs = []\n",
    "for p in notebook_dirs:\n",
    "    print(\"directory:\",p)\n",
    "    final_video = p / \"final_video.mp4\"\n",
    "    first_music = p / \"music.mp3\"\n",
    "    errored_file = p / \"errored.txt\"\n",
    "    if final_video.exists():\n",
    "        print(f\"âœ… Skipping {p} (final_video.mp4 exists)\", flush=True)\n",
    "    else:\n",
    "        print(f\"ğŸš€ final_video_doesn't exist: {p}\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
