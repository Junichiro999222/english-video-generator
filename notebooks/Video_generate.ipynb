{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ea708-fbb4-4841-9889-f54c07f8444a",
   "metadata": {
    "papermill": {
     "duration": 0.025213,
     "end_time": "2025-04-14T09:13:10.009137",
     "exception": false,
     "start_time": "2025-04-14T09:13:09.983924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def find_zombie_processes():\n",
    "    \"\"\"Find all zombie processes.\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run([\"ps\", \"aux\"], capture_output=True, text=True)\n",
    "        lines = result.stdout.split(\"\\n\")\n",
    "\n",
    "        zombie_pids = []\n",
    "        for line in lines:\n",
    "            parts = line.split()\n",
    "            if len(parts) > 7 and parts[7] == \"Z\":\n",
    "                pid = parts[1]  # PID is the second column\n",
    "                zombie_pids.append(pid)\n",
    "\n",
    "        return zombie_pids\n",
    "    except Exception as e:\n",
    "        print(f\"Error finding zombie processes: {e}\")\n",
    "        return []\n",
    "\n",
    "def kill_processes(pids):\n",
    "    \"\"\"Kill processes by PID.\"\"\"\n",
    "    for pid in pids:\n",
    "        try:\n",
    "            subprocess.run([\"sudo\", \"kill\", \"-9\", pid], check=True)\n",
    "            print(f\"âœ… Killed zombie process: {pid}\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Failed to kill process {pid}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    zombie_pids = find_zombie_processes()\n",
    "    if zombie_pids:\n",
    "        print(f\"ğŸ§Ÿ Found zombie processes: {zombie_pids}\")\n",
    "        kill_processes(zombie_pids)\n",
    "    else:\n",
    "        print(\"ğŸ‰ No zombie processes found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fef9a77-d075-4b18-85f9-29b69a962bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:13:10.023305Z",
     "iopub.status.busy": "2025-04-14T09:13:10.022727Z",
     "iopub.status.idle": "2025-04-14T09:13:10.053879Z",
     "shell.execute_reply": "2025-04-14T09:13:10.053230Z"
    },
    "papermill": {
     "duration": 0.038267,
     "end_time": "2025-04-14T09:13:10.054843",
     "exception": false,
     "start_time": "2025-04-14T09:13:10.016576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… No processes exceeded the threshold.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Set threshold in MiB (e.g. kill anything using more than 5000MiB)\n",
    "THRESHOLD_MB = 5000\n",
    "\n",
    "def get_gpu_processes():\n",
    "    result = subprocess.run(\n",
    "        [\"nvidia-smi\", \"--query-compute-apps=pid,used_memory\", \"--format=csv,noheader,nounits\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode != 0:\n",
    "        print(\"âŒ Error getting GPU process info\")\n",
    "        print(result.stderr)\n",
    "        return []\n",
    "\n",
    "    lines = result.stdout.strip().split('\\n')\n",
    "    processes = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            pid_str, mem_str = line.strip().split(',')\n",
    "            pid = int(pid_str)\n",
    "            mem = int(mem_str)\n",
    "            processes.append((pid, mem))\n",
    "        except ValueError:\n",
    "            continue  # skip malformed lines\n",
    "    return processes\n",
    "\n",
    "def kill_heavy_gpu_processes(threshold_mb=THRESHOLD_MB):\n",
    "    processes = get_gpu_processes()\n",
    "    killed = []\n",
    "    for pid, mem in processes:\n",
    "        if mem > threshold_mb:\n",
    "            try:\n",
    "                os.kill(pid, 9)\n",
    "                print(f\"ğŸ’€ Killed PID {pid} using {mem} MiB\")\n",
    "                killed.append(pid)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Failed to kill PID {pid}: {e}\")\n",
    "    if not killed:\n",
    "        print(\"âœ… No processes exceeded the threshold.\")\n",
    "    return killed\n",
    "\n",
    "# ğŸ§ª Run it\n",
    "if __name__ == \"__main__\":\n",
    "    kill_heavy_gpu_processes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcddfa7-0166-4d5f-87e6-052cde36daa8",
   "metadata": {
    "papermill": {
     "duration": 0.00415,
     "end_time": "2025-04-14T09:13:10.063522",
     "exception": false,
     "start_time": "2025-04-14T09:13:10.059372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73f2722-3011-4a74-a516-8124b40c27bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:13:10.072961Z",
     "iopub.status.busy": "2025-04-14T09:13:10.072468Z",
     "iopub.status.idle": "2025-04-14T09:13:13.003330Z",
     "shell.execute_reply": "2025-04-14T09:13:13.002550Z"
    },
    "papermill": {
     "duration": 2.936658,
     "end_time": "2025-04-14T09:13:13.004406",
     "exception": false,
     "start_time": "2025-04-14T09:13:10.067748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/share/fonts: caching, new cache contents: 0 fonts, 2 dirs\r\n",
      "/usr/share/fonts/X11: caching, new cache contents: 0 fonts, 3 dirs\r\n",
      "/usr/share/fonts/X11/encodings: caching, new cache contents: 0 fonts, 1 dirs\r\n",
      "/usr/share/fonts/X11/encodings/large: caching, new cache contents: 0 fonts, 0 dirs\r\n",
      "/usr/share/fonts/X11/misc: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caching, new cache contents: 89 fonts, 0 dirs\r\n",
      "/usr/share/fonts/X11/util: caching, new cache contents: 0 fonts, 0 dirs\r\n",
      "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 1 dirs\r\n",
      "/usr/share/fonts/truetype/dejavu: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caching, new cache contents: 6 fonts, 0 dirs\r\n",
      "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\r\n",
      "/home/ubuntu/.local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\r\n",
      "/home/ubuntu/.fonts: caching, new cache contents: 2 fonts, 0 dirs\r\n",
      "/usr/share/fonts/X11: skipping, looped directory detected\r\n",
      "/usr/share/fonts/truetype: skipping, looped directory detected\r\n",
      "/usr/share/fonts/X11/encodings: skipping, looped directory detected\r\n",
      "/usr/share/fonts/X11/misc: skipping, looped directory detected\r\n",
      "/usr/share/fonts/X11/util: skipping, looped directory detected\r\n",
      "/usr/share/fonts/truetype/dejavu: skipping, looped directory detected\r\n",
      "/usr/share/fonts/X11/encodings/large: skipping, looped directory detected\r\n",
      "/var/cache/fontconfig: not cleaning unwritable cache directory\r\n",
      "/home/ubuntu/.cache/fontconfig: cleaning cache directory\r\n",
      "/home/ubuntu/.fontconfig: not cleaning non-existent cache directory\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc-cache: succeeded\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.fonts/Valty_DEMO.otf: Valty DEMO:style=Bold Italic\r\n",
      "/home/ubuntu/.fonts/nicomoji-plus_v2-5.ttf: NicoMoji+v2,ãƒ‹ã‚³ãƒ¢ã‚¸ï¼‹v2:style=Regular\r\n"
     ]
    }
   ],
   "source": [
    "# !pip install pydub moviepy librosa\n",
    "# !conda install -y -c conda-forge ffmpeg\n",
    "# !pip install gTTS openai\n",
    "# !pip install opencv-python\n",
    "# !pip install torch\n",
    "# !pip install git+https://github.com/openai/whisper.git\n",
    "# !pip install boto3\n",
    "# !pip install pathlib\n",
    "\n",
    "\n",
    "!mkdir -p ~/.fonts\n",
    "!mkdir -p ~/.local/share/fonts\n",
    "\n",
    "!cp ../../src/fonts/nicomoji-plus_v2-5.ttf ~/.fonts/\n",
    "!cp ../../src/fonts/Valty_DEMO.otf ~/.fonts/\n",
    "\n",
    "!fc-cache -fv\n",
    "!fc-list | grep \"Valty\\|nicomoji\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637b39e-c147-4856-8f20-ce25ccfe04cc",
   "metadata": {
    "papermill": {
     "duration": 0.004714,
     "end_time": "2025-04-14T09:13:13.016603",
     "exception": false,
     "start_time": "2025-04-14T09:13:13.011889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19382c70-cc32-4fdc-adc4-3206b4a04134",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:13:13.026710Z",
     "iopub.status.busy": "2025-04-14T09:13:13.026465Z",
     "iopub.status.idle": "2025-04-14T09:13:59.222590Z",
     "shell.execute_reply": "2025-04-14T09:13:59.222014Z"
    },
    "papermill": {
     "duration": 46.206319,
     "end_time": "2025-04-14T09:13:59.227488",
     "exception": false,
     "start_time": "2025-04-14T09:13:13.021169",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸµ Improved Lyrics:\n",
      " ---\n",
      "[17.06s - 24.76s]  You got mad on your face, you big disgrace, kicking your can all over the place, singing\n",
      "[24.76s - 28.42s]  We will, we will rock you\n",
      "[30.56s - 34.38s]  We will, we will rock you\n",
      "[36.18s - 41.94s]  But you're a young man, hot man, shouting in the street, gonna take on the world someday\n",
      "[41.94s - 47.94s]  You got blood on your face, you big disgrace, waving your banner all over the place\n",
      "[47.94s - 52.24s]  We will, we will rock you\n",
      "[54.16s - 58.08s]  We will, we will rock you\n",
      "[59.88s - 65.50s]  But you're an old man, poor man, pleading with your eyes, gonna make you some beef someday\n",
      "[65.50s - 71.54s]  You got mud on your face, big disgrace, somebody better put your bag into your place\n",
      "[71.54s - 75.72s]  We will, we will rock you\n",
      "[75.72s - 81.82s]  We will, we will rock you\n",
      "[83.48s - 87.50s]  We will, we will rock you\n",
      "[88.42s - 93.32s]  We will, we will rock you\n",
      "[93.32s - 95.32s]  Alright\n",
      "[118.42s - 120.50s]  We will, we will rock you\n",
      "[120.50s - 121.46s]  We will, we will rock you\n",
      "[121.46s - 121.84s]  We will, we will rock you\n",
      "[121.84s - 122.00s]  We will, we will rock you\n",
      "[122.00s - 122.00s] \n",
      "[122.00s - 122.00s] \n",
      "[122.00s - 122.00s] \n",
      "[122.00s - 122.00s] \n",
      "[122.00s - 122.00s] \n",
      "[122.00s - 122.00s] \n",
      "[122.00s - 122.00s] \n",
      "[122.00s - 122.00s] \n",
      "[122.00s - 122.00s] \n",
      "[122.00s - 122.00s] \n",
      "[122.00s - 122.00s] \n",
      "\n",
      "âœ… Split lyrics with timestamps saved in split_lyrics.txt!\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()  # Clears unused GPU memory\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)  # Show memory usage\n",
    "\n",
    "# ğŸ¤ Load the \"large\" Whisper model\n",
    "model = whisper.load_model(\"large\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# ğŸ§ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ‹¡å¼µå­é †ã«æ¢ç´¢\n",
    "for ext in [\".mp3\", \".m4a\", \".opus\"]:\n",
    "    candidate = Path(f\"music{ext}\")\n",
    "    if candidate.exists():\n",
    "        audio_file = str(candidate)\n",
    "        break\n",
    "else:\n",
    "    raise FileNotFoundError(\"ğŸ§ Audio file not found!\")\n",
    "\n",
    "# ğŸ§  Whisperã§æ–‡å­—èµ·ã“ã—ï¼\n",
    "result = model.transcribe(\n",
    "    audio_file,\n",
    "    temperature=0,\n",
    "    condition_on_previous_text=True,\n",
    "    best_of=10,\n",
    "    word_timestamps=True,\n",
    "    beam_size=10,\n",
    "    language=\"en\"\n",
    ")\n",
    "\n",
    "\n",
    "# ğŸ“ Extract transcribed segments\n",
    "segments = result[\"segments\"]\n",
    "\n",
    "# Function to format timestamps for ASS subtitles\n",
    "def ass_timestamp(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    ms = int((seconds - int(seconds)) * 100)\n",
    "    return f\"{h}:{m:02}:{s:02}.{ms:02}\"\n",
    "\n",
    "buffer = 0.3\n",
    "# ğŸ’¾ Save transcriptions with timestamps\n",
    "with open(\"split_lyrics.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for seg in segments:\n",
    "        start = seg['start']\n",
    "        end = seg['end'] + buffer  # çµ‚äº†æ™‚é–“ã«ä½™è£•ã‚’æŒãŸã›ã‚‹\n",
    "        f.write(f\"[{start:.2f}s - {end:.2f}s] {seg['text']}\\n\")\n",
    "\n",
    "# ğŸ¤ Print formatted lyrics\n",
    "print(\"\\nğŸµ Improved Lyrics:\\n ---\")\n",
    "for seg in segments:\n",
    "    print(f\"[{seg['start']:.2f}s - {seg['end']:.2f}s] {seg['text']}\")\n",
    "\n",
    "print(\"\\nâœ… Split lyrics with timestamps saved in split_lyrics.txt!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c42cef-167a-4ed8-a0ba-15b2db02801e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:13:59.240930Z",
     "iopub.status.busy": "2025-04-14T09:13:59.240452Z",
     "iopub.status.idle": "2025-04-14T09:14:17.921932Z",
     "shell.execute_reply": "2025-04-14T09:14:17.921353Z"
    },
    "papermill": {
     "duration": 18.688159,
     "end_time": "2025-04-14T09:14:17.922864",
     "exception": false,
     "start_time": "2025-04-14T09:13:59.234705",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ€ GPTã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...ï¼ˆè©¦è¡Œ 1 å›ç›®ï¼‰\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä¿®æ­£æ¸ˆã¿ã®æ­Œè©ã‚’ corrected_lyrics_with_timestamps.txt ã«ä¿å­˜ã—ãŸã®ã ï¼\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import time\n",
    "import json\n",
    "\n",
    "# ğŸ” Whisperã§å–å¾—ã—ãŸæ­Œè©ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿\n",
    "with open(\"split_lyrics.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lyrics_with_timestamps = f.read()\n",
    "\n",
    "client = openai.OpenAI(api_key=\"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\")\n",
    "\n",
    "max_retries = 3\n",
    "delay = 10  # ç§’\n",
    "\n",
    "for attempt in range(1, max_retries + 1):\n",
    "    try:\n",
    "        print(f\"ğŸŒ€ GPTã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸­...ï¼ˆè©¦è¡Œ {attempt} å›ç›®ï¼‰\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a lyrics correction assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"The following is a transcribed song lyrics with timestamps. \n",
    "However, there are some misrecognized words and phrases. \n",
    "\n",
    "Your task:\n",
    "1. **Correct any transcription errors** and **ensure proper grammar and structure**.\n",
    "2. **Remove unnecessary filler words** like 'uh', 'yeah', 'oh' (if they are not part of the lyrics).\n",
    "3. **Keep timestamps in their original format**.\n",
    "4. **Return the corrected lyrics with timestamps in the same format** as provided.\n",
    "5. **Skip the duplicate phrases**\n",
    "\n",
    "Here is the transcribed lyrics:\n",
    "---\n",
    "{lyrics_with_timestamps}\n",
    "---\n",
    "Now, please return the **corrected version**.\"\"\"}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        gpt_response = response.choices[0].message.content.strip()\n",
    "\n",
    "        if not gpt_response:\n",
    "            raise ValueError(\"Empty response from GPT-4\")\n",
    "\n",
    "        # ğŸ’¾ ä¿®æ­£æ¸ˆã¿æ­Œè©ã‚’ä¿å­˜\n",
    "        with open(\"corrected_lyrics_with_timestamps.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(gpt_response)\n",
    "\n",
    "        print(\"âœ… ä¿®æ­£æ¸ˆã¿ã®æ­Œè©ã‚’ corrected_lyrics_with_timestamps.txt ã«ä¿å­˜ã—ãŸã®ã ï¼\")\n",
    "        break  # æˆåŠŸã—ãŸã®ã§ãƒ«ãƒ¼ãƒ—è„±å‡ºï¼\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ˆ{type(e).__name__}ï¼‰: {e}\")\n",
    "        if attempt == max_retries:\n",
    "            raise RuntimeError(\"âŒ GPT-4ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã™ã¹ã¦å¤±æ•—ã—ãŸã®ã â€¦\") from e\n",
    "        else:\n",
    "            print(f\"â³ {delay}ç§’å¾…ã£ã¦å†è©¦è¡Œã™ã‚‹ã®ã â€¦\")\n",
    "            time.sleep(delay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15870be4-6c56-494c-a4de-7d832c662838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:14:17.936776Z",
     "iopub.status.busy": "2025-04-14T09:14:17.936354Z",
     "iopub.status.idle": "2025-04-14T09:14:29.278964Z",
     "shell.execute_reply": "2025-04-14T09:14:29.278432Z"
    },
    "papermill": {
     "duration": 11.349235,
     "end_time": "2025-04-14T09:14:29.279787",
     "exception": false,
     "start_time": "2025-04-14T09:14:17.930552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤ 1ç•ªã®æ™‚åˆ»æ¨å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆè©¦è¡Œ1ï¼‰\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 1ç•ªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å–å¾—æˆåŠŸãªã®ã ï¼ {'start_time': 17.06, 'end_time': 58.38}\n",
      "âœ… 1ç•ªã®é–‹å§‹ãƒ»çµ‚äº†æ™‚é–“ã‚’ first_verse_timestamps.txt ã«ä¿å­˜ã—ãŸã®ã ï¼ {'start_time': 17.06, 'end_time': 58.38}\n",
      "ğŸ¶ 1ç•ªã®æ­Œè©æ•´å½¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆè©¦è¡Œ1ï¼‰\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ•´å½¢æ¸ˆã¿ï¼†åˆ†å‰²æ¸ˆã¿ã®æ­Œè©ã‚’ formatted_lyrics.json ã«ä¿å­˜ã—ãŸã®ã ï¼ [{'text': 'You got mud on your face, you big disgrace, kicking your can all over the place, singing', 'start': 17.06, 'end': 25.06}, {'text': 'We will, we will rock you', 'start': 24.76, 'end': 28.72}, {'text': \"You're a young man, hard man, shouting in the street, gonna take on the world someday\", 'start': 36.18, 'end': 42.24}, {'text': 'You got blood on your face, you big disgrace, waving your banner all over the place', 'start': 41.94, 'end': 48.24}, {'text': 'We will, we will rock you', 'start': 47.94, 'end': 52.54}]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "import time\n",
    "\n",
    "client = openai.OpenAI(api_key=\"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\")\n",
    "\n",
    "max_retries = 5\n",
    "delay = 10\n",
    "\n",
    "# ğŸ” ä¿®æ­£æ¸ˆã¿ã®æ­Œè©ã‚’èª­ã¿è¾¼ã‚€\n",
    "with open(\"corrected_lyrics_with_timestamps.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lyrics_with_timestamps = f.read()\n",
    "\n",
    "\n",
    "# === 1. GPTã«1ç•ªã®é–‹å§‹ãƒ»çµ‚äº†ã‚’èã ===\n",
    "max_retries = 3\n",
    "delay = 3  # ç§’\n",
    "\n",
    "for attempt in range(1, max_retries + 1):\n",
    "    try:\n",
    "        print(f\"ğŸ¤ 1ç•ªã®æ™‚åˆ»æ¨å®šãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆè©¦è¡Œ{attempt}ï¼‰\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a lyrics processing assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"The following is a corrected song lyrics with timestamps:\n",
    "---\n",
    "{lyrics_with_timestamps}\n",
    "---\n",
    "\n",
    "Your task:\n",
    "1. Identify where the **first verse starts and ends**.\n",
    "2. The **end** timestamp should be **approximately halfway through the full lyrics**.\n",
    "3. The **end** timestamp should be over 50 seconds. \n",
    "4. Provide the **exact timestamps** for the first verse.\n",
    "5. Return the timestamps **ONLY** in the following JSON format, no any instructions :\n",
    "{{\n",
    "    \"start_time\": 12.50,\n",
    "    \"end_time\": 80.30\n",
    "}}\n",
    "\"\"\"}\n",
    "            ]\n",
    "        )\n",
    "        gpt_response = response.choices[0].message.content.strip()\n",
    "\n",
    "        # ğŸ‘‡ ç©ºã£ã½ãªã‚‰ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦ãƒªãƒˆãƒ©ã‚¤ã¸\n",
    "        if not gpt_response:\n",
    "            raise ValueError(\"Empty response from GPT-4\")\n",
    "\n",
    "        first_verse_info = json.loads(gpt_response)\n",
    "        print(\"âœ… 1ç•ªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å–å¾—æˆåŠŸãªã®ã ï¼\", first_verse_info)\n",
    "        # ğŸ’¾ 1ç•ªã®æ™‚é–“æƒ…å ±ã‚’ä¿å­˜\n",
    "        with open(\"first_verse_timestamps.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(first_verse_info, f, indent=4)\n",
    "        \n",
    "        print(\"âœ… 1ç•ªã®é–‹å§‹ãƒ»çµ‚äº†æ™‚é–“ã‚’ first_verse_timestamps.txt ã«ä¿å­˜ã—ãŸã®ã ï¼\",first_verse_info)\n",
    "        break  # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ãƒªãƒˆãƒ©ã‚¤ {attempt}/{max_retries} å›ç›®ã§ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}\")\n",
    "        if attempt == max_retries:\n",
    "            raise RuntimeError(\"âŒ 1ç•ªã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å–å¾—ã«ã™ã¹ã¦å¤±æ•—ã—ãŸã®ã â€¦\") from e\n",
    "        time.sleep(delay)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# === 2. 1ç•ªã ã‘ã‚’æŠ½å‡ºã—ã¦æ•´å½¢ï¼†åˆ†å‰² ===\n",
    "formatted_lyrics = None\n",
    "for attempt in range(1, max_retries + 1):\n",
    "    try:\n",
    "        print(f\"ğŸ¶ 1ç•ªã®æ­Œè©æ•´å½¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆè©¦è¡Œ{attempt}ï¼‰\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a lyrics processing assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"\n",
    "---\n",
    "{lyrics_with_timestamps}\n",
    "---\n",
    "\n",
    "The first verse starts at {first_verse_info[\"start_time\"]}s and ends at {first_verse_info[\"end_time\"]}s.\n",
    "\n",
    "Your next task:\n",
    "1. Extract **only** the lyrics within these timestamps.\n",
    "2. Format the lyrics neatly.\n",
    "3. Split the lyrics into **natural phrases** with timestamps.\n",
    "4. **Skip the phrases that almost the same to already existing phrases.\n",
    "5. Without any slash \"/\" in the sentence.\n",
    "Return your answer in JSON format like this without any instruction:\n",
    "[\n",
    "    {{\"text\": \"Tonight I'm gonna have myself a real good time\", \"start\": 12.50, \"end\": 15.80}},\n",
    "    {{\"text\": \"I feel alive\", \"start\": 15.80, \"end\": 17.30}},\n",
    "    ...\n",
    "]\n",
    "\"\"\"}\n",
    "            ]\n",
    "        )\n",
    "        gpt_response = response.choices[0].message.content.strip()\n",
    "        formatted_lyrics = json.loads(gpt_response)\n",
    "\n",
    "        with open(\"formatted_lyrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(formatted_lyrics, f, indent=4)\n",
    "\n",
    "        print(\"âœ… æ•´å½¢æ¸ˆã¿ï¼†åˆ†å‰²æ¸ˆã¿ã®æ­Œè©ã‚’ formatted_lyrics.json ã«ä¿å­˜ã—ãŸã®ã ï¼\", formatted_lyrics)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ˆ{type(e).__name__}ï¼‰: {e}\")\n",
    "        if attempt == max_retries:\n",
    "            raise RuntimeError(\"âŒ æ­Œè©æ•´å½¢ï¼†åˆ†å‰²ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã™ã¹ã¦å¤±æ•—ã—ãŸã®ã â€¦\") from e\n",
    "        time.sleep(delay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cd676e3-4d38-4f5a-b662-d4551b6dccbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:14:29.293757Z",
     "iopub.status.busy": "2025-04-14T09:14:29.293220Z",
     "iopub.status.idle": "2025-04-14T09:15:02.251831Z",
     "shell.execute_reply": "2025-04-14T09:15:02.251250Z"
    },
    "papermill": {
     "duration": 32.965413,
     "end_time": "2025-04-14T09:15:02.252752",
     "exception": false,
     "start_time": "2025-04-14T09:14:29.287339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… phrase_1_eng.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆYou got mud on your face, you big disgrace, kicking your can all over the place, singingï¼‰\n",
      "âœ… phrase_1_eng_2.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆYou got mud on your face, you big disgrace, kicking your can all over the place, singingï¼‰\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ç¿»è¨³å®Œäº†: é¡”ã«æ³¥ã‚’å¡—ã‚‰ã‚Œã¦ã€å¤§æ¥ã‚’ã‹ã„ã¦ã‚‹ã•ã€‚ç¼¶è¹´ã‚Šã—ã¦ã°ã‹ã‚Šã§ã€ã‚ã¡ã“ã¡ã«æ•£ã‚‰ã°ã£ã¦ã€æ­Œã£ã¦ã„ã‚‹ã‚“ã ã€‚\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ phrase_1_zunda.wav saved! (é¡”ã«æ³¥ã‚’å¡—ã‚‰ã‚Œã¦ã€å¤§æ¥ã‚’ã‹ã„ã¦ã‚‹ã•ã€‚ç¼¶è¹´ã‚Šã—ã¦ã°ã‹ã‚Šã§ã€ã‚ã¡ã“ã¡ã«æ•£ã‚‰ã°ã£ã¦ã€æ­Œã£ã¦ã„ã‚‹ã‚“ã ã€‚)\n",
      "âœ… phrase_2_eng.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆWe will, we will rock youï¼‰\n",
      "âœ… phrase_2_eng_2.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆWe will, we will rock youï¼‰\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ç¿»è¨³å®Œäº†: ç§ãŸã¡ã¯ã€ç§ãŸã¡ã¯ã€ã‚ãªãŸã‚’æºã•ã¶ã‚‹ã®ã \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ phrase_2_zunda.wav saved! (ç§ãŸã¡ã¯ã€ç§ãŸã¡ã¯ã€ã‚ãªãŸã‚’æºã•ã¶ã‚‹ã®ã )\n",
      "âœ… phrase_3_eng.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆYou're a young man, hard man, shouting in the street, gonna take on the world somedayï¼‰\n",
      "âœ… phrase_3_eng_2.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆYou're a young man, hard man, shouting in the street, gonna take on the world somedayï¼‰\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ç¿»è¨³å®Œäº†: å›ã¯è‹¥è€…ã§ã€ç¡¬ã„ç”·ã€é€šã‚Šã§å«ã‚“ã§ã„ã‚‹ã€ã„ã¤ã‹ã“ã®ä¸–ç•Œã‚’æ‰‹ã«å…¥ã‚Œã‚‹ã‚“ã \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ phrase_3_zunda.wav saved! (å›ã¯è‹¥è€…ã§ã€ç¡¬ã„ç”·ã€é€šã‚Šã§å«ã‚“ã§ã„ã‚‹ã€ã„ã¤ã‹ã“ã®ä¸–ç•Œã‚’æ‰‹ã«å…¥ã‚Œã‚‹ã‚“ã )\n",
      "âœ… phrase_4_eng.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆYou got blood on your face, you big disgrace, waving your banner all over the placeï¼‰\n",
      "âœ… phrase_4_eng_2.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆYou got blood on your face, you big disgrace, waving your banner all over the placeï¼‰\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ç¿»è¨³å®Œäº†: å›ã®é¡”ã«ã¯è¡€ãŒã¤ã„ã¦ã„ã¦ã€å¤§ããªæ¥ã•ã‚‰ã—ã€å›ã®æ——ã‚’ã‚ã¡ã“ã¡ã§æŒ¯ã‚Šå›ã—ã¦ã„ã‚‹ã®ã ã€‚\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ phrase_4_zunda.wav saved! (å›ã®é¡”ã«ã¯è¡€ãŒã¤ã„ã¦ã„ã¦ã€å¤§ããªæ¥ã•ã‚‰ã—ã€å›ã®æ——ã‚’ã‚ã¡ã“ã¡ã§æŒ¯ã‚Šå›ã—ã¦ã„ã‚‹ã®ã ã€‚)\n",
      "âœ… phrase_5_eng.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆWe will, we will rock youï¼‰\n",
      "âœ… phrase_5_eng_2.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆWe will, we will rock youï¼‰\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ç¿»è¨³å®Œäº†: ç§ãŸã¡ã¯ã€ç§ãŸã¡ã¯ã€ã‚ãªãŸã‚’æºã•ã¶ã‚‹ã®ã \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ™ phrase_5_zunda.wav saved! (ç§ãŸã¡ã¯ã€ç§ãŸã¡ã¯ã€ã‚ãªãŸã‚’æºã•ã¶ã‚‹ã®ã )\n",
      "ğŸ‰ ã™ã¹ã¦ã®ãƒ•ãƒ¬ãƒ¼ã‚ºå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼\n",
      "âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ processed_data.json ã«ä¿å­˜ï¼\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydub import AudioSegment\n",
    "from gtts import gTTS\n",
    "import openai\n",
    "import subprocess\n",
    "import requests\n",
    "import boto3\n",
    "\n",
    "# âœ… OpenAI APIã‚­ãƒ¼ï¼ˆç’°å¢ƒå¤‰æ•°ã«è¨­å®šæ¸ˆã¿ãªã‚‰ä¸è¦ï¼‰\n",
    "api_key = \"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\"\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "# âœ… ãšã‚“ã ã‚‚ã‚“ã® VOICEVOX éŸ³å£°IDï¼ˆãƒãƒ¼ãƒãƒ«ï¼‰\n",
    "# ZUNDAMON_VOICE_ID = 3  \n",
    "# VOICEVOX_URL = \"http://127.0.0.1:50021\"\n",
    "# âœ… Your API Key\n",
    "API_KEY = \"u-A78-362898440\"  # Replace with your actual API key\n",
    "# âœ… VOICEVOX API URL\n",
    "VOICEVOX_API_URL = \"https://api.su-shiki.com/v2/voicevox/audio/\"  # âœ… Fixed URL\n",
    "# âœ… Zundamon Voice ID\n",
    "ZUNDAMON_VOICE_ID = 3  # (ãƒãƒ¼ãƒãƒ« Zundamon)\n",
    "polly = boto3.client(\"polly\", region_name=\"us-east-1\")  # ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¯ãŠå¥½ã¿ã§\n",
    "\n",
    "\n",
    "# ğŸµ 1ç•ªã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ JSON ã‹ã‚‰èª­ã¿è¾¼ã‚€\n",
    "with open(\"formatted_lyrics.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    timestamps = json.load(f)  # JSONã‚’è¾æ›¸å‹ã«å¤‰æ›\n",
    "\n",
    "\n",
    "# ğŸµ å…ƒã®MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "audio = AudioSegment.from_file(audio_file)\n",
    "\n",
    "# ğŸ“‚ ãƒªã‚¹ãƒˆã‚’ç”¨æ„ï¼ˆè‹±èªéŸ³å£°ãƒ»ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆãƒ»æ—¥æœ¬èªéŸ³å£°ï¼‰\n",
    "# ğŸ“‚ å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚¹ãƒˆåŒ–ï¼ˆè‹±èªéŸ³å£°ãƒ»ç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆãƒ»ãšã‚“ã ã‚‚ã‚“éŸ³å£°ï¼‰\n",
    "english_audio_files = []\n",
    "english_audio_files_2 = []\n",
    "translated_texts = []\n",
    "zundamon_audio_files = []\n",
    "\n",
    "\n",
    "# ğŸ”ª éŸ³å£°ã‚’ãƒ•ãƒ¬ãƒ¼ã‚ºã”ã¨ã«ã‚«ãƒƒãƒˆï¼†ç¿»è¨³ï¼†æ—¥æœ¬èªéŸ³å£°ç”Ÿæˆ\n",
    "for i, segment in enumerate(timestamps):\n",
    "    start_ms = int(segment[\"start\"] * 1000)  # ç§’ â†’ ãƒŸãƒªç§’å¤‰æ›\n",
    "    end_ms = int(segment[\"end\"] * 1000)\n",
    "    \n",
    "    # print(f\"Processing segment {i+1}: {segment['text']} ({start_ms}ms - {end_ms}ms)\")\n",
    "    \n",
    "    # ğŸ¶ ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’ã‚«ãƒƒãƒˆ\n",
    "    phrase_audio = audio[start_ms:end_ms]\n",
    "    \n",
    "    # ğŸ’¾ è‹±èªã®éŸ³å£°ã‚’ä¿å­˜\n",
    "    eng_filename = f\"phrase_{i+1}_eng.wav\"\n",
    "    phrase_audio.export(eng_filename, format=\"wav\")\n",
    "    english_audio_files.append(eng_filename)\n",
    "    \n",
    "    print(f\"âœ… {eng_filename} ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆ{segment['text']}ï¼‰\")\n",
    "\n",
    "    \n",
    "    # ğŸŒ gTTS ã§æ•™ç§‘æ›¸ã¿ãŸã„ãªè‹±èªã‚’ç”Ÿæˆ\n",
    "    # ğŸ’¾ WAV ã«å¤‰æ›ã—ã¦ä¿å­˜\n",
    "    eng_filename_2 = f\"phrase_{i+1}_eng_2.wav\"\n",
    "    response = polly.synthesize_speech(\n",
    "        Text=segment['text'],\n",
    "        OutputFormat=\"mp3\",\n",
    "        VoiceId=\"Ruth\",\n",
    "        Engine=\"neural\",\n",
    "    )\n",
    "    with open(\"temp.mp3\", \"wb\") as f:\n",
    "        f.write(response[\"AudioStream\"].read())\n",
    "    AudioSegment.from_file(\"temp.mp3\").export(eng_filename_2, format=\"wav\")  # WAV ã«å¤‰æ›\n",
    "    english_audio_files_2.append(eng_filename_2)\n",
    "\n",
    "    \n",
    "    print(f\"âœ… {eng_filename_2} ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ï¼ˆ{segment['text']}ï¼‰\")\n",
    "\n",
    "    \n",
    "    # ğŸŒ GPT-4 ã§å’Œè¨³\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a professional English-Japanese translator. \\\n",
    "            Translate the given the snippets of English song lyrics into natural Japanese, \\\n",
    "            you should refer the full lyrics for accurate translation,\\\n",
    "            and make sure to add a cute ending such as 'ã®ã ' or 'ãªã®ã ' at the end.But not'ãªã®ã ã‚ˆ'\"},\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"The full lyrics is shown below\n",
    "            ---\n",
    "            {timestamps}\n",
    "            ---\n",
    "            Translate the following song lyrics to natural Japanese:\\n\\n{segment['text']}\\n\n",
    "\"\"\"}\n",
    "            \n",
    "        ]\n",
    "    )\n",
    "    translated_text = response.choices[0].message.content.strip()\n",
    "    translated_texts.append(translated_text)\n",
    "\n",
    "    print(f\"ğŸ“ ç¿»è¨³å®Œäº†: {translated_text}\")\n",
    "\n",
    "    # ğŸ¤ Generate Zundamon's voice using VOICEVOX Cloud API with speed control\n",
    "    params = {\n",
    "        \"text\": translated_text,\n",
    "        \"speaker\": ZUNDAMON_VOICE_ID,\n",
    "        \"key\": API_KEY,\n",
    "        \"speedScale\": 1.3  # ğŸ”¥ Set desired speed (1.0 is normal speed, 1.3 is faster)\n",
    "    }\n",
    "    \n",
    "    response = requests.get(VOICEVOX_API_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        zunda_filename = f\"phrase_{i+1}_zunda.wav\"\n",
    "        with open(zunda_filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "    \n",
    "        zundamon_audio_files.append(zunda_filename)  # Add the generated file to the list\n",
    "        print(f\"ğŸ™ {zunda_filename} saved! ({translated_text})\")\n",
    "    else:\n",
    "        print(f\"âŒ Failed to generate Zundamon voice: {response.text}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ğŸ‰ ã™ã¹ã¦ã®ãƒ•ãƒ¬ãƒ¼ã‚ºå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼ï¼\")\n",
    "\n",
    "# ğŸ’¾ ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆå¾Œã§åˆæˆã«ä½¿ã†ï¼‰\n",
    "data = {\n",
    "    \"english_audio\": english_audio_files,\n",
    "    \"english_audio_2\": english_audio_files_2,\n",
    "    \"translated_texts\": translated_texts,\n",
    "    \"japanese_audio\": zundamon_audio_files\n",
    "}\n",
    "\n",
    "with open(\"processed_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ processed_data.json ã«ä¿å­˜ï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28ac310a-897c-4368-8cf7-04c25be855db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:15:02.267866Z",
     "iopub.status.busy": "2025-04-14T09:15:02.267447Z",
     "iopub.status.idle": "2025-04-14T09:15:02.511569Z",
     "shell.execute_reply": "2025-04-14T09:15:02.511006Z"
    },
    "papermill": {
     "duration": 0.251456,
     "end_time": "2025-04-14T09:15:02.512407",
     "exception": false,
     "start_time": "2025-04-14T09:15:02.260951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… first_verse.wav ã‚’ä¿å­˜ã—ãŸã®ã ï¼\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š\n",
    "original_audio_file = \"music.mp3\"  # å…ƒéŸ³æº\n",
    "timestamps_file = \"first_verse_timestamps.txt\"  # 1ç•ªã®é–‹å§‹ãƒ»çµ‚äº†æ™‚é–“ãŒå…¥ã£ãŸJSON\n",
    "output_audio_file = \"first_verse.wav\"  # 1ç•ªã ã‘ã®éŸ³æº\n",
    "\n",
    "# ğŸµ éŸ³å£°ã‚’èª­ã¿è¾¼ã¿\n",
    "original_audio = AudioSegment.from_file(original_audio_file)\n",
    "\n",
    "# ğŸ•’ **JSONã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦çµ‚äº†æ™‚é–“ã‚’å–å¾—**\n",
    "with open(timestamps_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    timestamps = json.load(f)  # JSONã‚’è¾æ›¸ã¨ã—ã¦èª­ã¿è¾¼ã‚€\n",
    "    end_time = float(timestamps[\"end_time\"]) * 1000  # ç§’ â†’ ãƒŸãƒªç§’å¤‰æ›\n",
    "\n",
    "# ğŸ¶ **1ç•ªã ã‘ã‚’åˆ‡ã‚Šå‡ºã—**ï¼ˆé–‹å§‹æ™‚é–“ã¯ 0 ç§’å›ºå®šï¼‰\n",
    "first_verse_audio = original_audio[:int(end_time+3000)]\n",
    "\n",
    "# ğŸšï¸ **ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆã‚’é©ç”¨**\n",
    "first_verse_audio = first_verse_audio.fade_out(3000)  # 3ç§’ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ\n",
    "\n",
    "# ğŸ’¾ **ä¿å­˜**\n",
    "first_verse_audio.export(output_audio_file, format=\"wav\")\n",
    "print(f\"âœ… {output_audio_file} ã‚’ä¿å­˜ã—ãŸã®ã ï¼\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d227ed5-c72d-4199-89b9-e6fb1a44ff95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:15:02.527521Z",
     "iopub.status.busy": "2025-04-14T09:15:02.527078Z",
     "iopub.status.idle": "2025-04-14T09:15:06.326502Z",
     "shell.execute_reply": "2025-04-14T09:15:06.325934Z"
    },
    "papermill": {
     "duration": 3.806656,
     "end_time": "2025-04-14T09:15:06.327369",
     "exception": false,
     "start_time": "2025-04-14T09:15:02.520713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… final_output.mp3 ã‚’ä½œæˆã—ãŸã®ã ï¼ï¼ğŸ”¥\n",
      "âœ… final_output.json ã‚‚ä½œæˆã—ãŸã®ã ï¼ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import json\n",
    "\n",
    "# ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š\n",
    "original_audio_file = \"first_verse.wav\"  # 1ç•ªã ã‘ã®å…ƒéŸ³æº\n",
    "chime_file = \"../../src/sounds/Bell_Accent06-1(Dry).mp3\"  # æ³¨æ„æ›¸ãã®å‰ã®ãƒãƒ£ã‚¤ãƒ éŸ³\n",
    "first_verse_file = \"first_verse.wav\"\n",
    "processed_data_file = \"processed_data.json\"\n",
    "formatted_lyrics_file = \"formatted_lyrics.json\"\n",
    "\n",
    "output_audio_file = \"final_output.mp3\"  # æœ€çµ‚çš„ãªåˆæˆéŸ³å£°\n",
    "output_json_file = \"final_output.json\"  # å‹•ç”»ç”¨ã®JSONãƒ‡ãƒ¼ã‚¿\n",
    "\n",
    "json_data = []\n",
    "# ğŸ”„ **ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰**\n",
    "with open(processed_data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "with open(formatted_lyrics_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lyrics_data = json.load(f)\n",
    "\n",
    "# ğŸµ **1ç•ªã®éŸ³æºã‚’ãƒ­ãƒ¼ãƒ‰**\n",
    "first_verse = AudioSegment.from_file(first_verse_file, format=\"mp3\")\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(chime_file):\n",
    "    raise FileNotFoundError(f\"File not found: {chime_file}\")\n",
    "\n",
    "# ğŸ”” **ãƒãƒ£ã‚¤ãƒ ã¨é–“ï¼ˆæ•°ç§’ï¼‰**\n",
    "chime = AudioSegment.from_file(chime_file, format=\"mp3\")\n",
    "silence = AudioSegment.silent(duration=500)  # 1ç§’ã®ç„¡éŸ³\n",
    "silence_2 = AudioSegment.silent(duration=3000)  # 1ç§’ã®ç„¡éŸ³\n",
    "\n",
    "# ğŸ¶ **éŸ³å£°çµåˆé–‹å§‹ï¼**\n",
    "final_audio = chime + silence + silence + silence # æœ€åˆã«ãƒãƒ£ã‚¤ãƒ ã¨ç„¡éŸ³\n",
    "# ğŸ“œ **JSONã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ **\n",
    "json_data.append({\n",
    "    \"index\": 0,\n",
    "    \"original_text\": \"chime\",\n",
    "    \"translated_text\": \"chime\",\n",
    "    \"end_time\": len(final_audio) / 1000,  # ç§’ã«å¤‰æ›\n",
    "    \"type\":\"bridge\",\n",
    "    \n",
    "})\n",
    "\n",
    "final_audio +=  silence # æœ€åˆã«ãƒãƒ£ã‚¤ãƒ ã¨ç„¡éŸ³\n",
    "# ğŸ“œ **JSONã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ **\n",
    "json_data.append({\n",
    "    \"index\": 1,\n",
    "    \"original_text\": \"silence\",\n",
    "    \"translated_text\": \"silence\",\n",
    "    \"end_time\": len(final_audio) / 1000,  # ç§’ã«å¤‰æ›\n",
    "    \"type\":\"bridge\",\n",
    "    \n",
    "})\n",
    "\n",
    "final_audio += first_verse + silence  # 1ç•ª\n",
    "# ğŸ“œ **JSONã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ **\n",
    "json_data.append({\n",
    "    \"index\": 2,\n",
    "    \"original_text\": \"first_verse\",\n",
    "    \"translated_text\": \"first_verse\",\n",
    "    \"end_time\": len(final_audio) / 1000,  # ç§’ã«å¤‰æ›\n",
    "    \"type\":\"bridge\",\n",
    "    \n",
    "})\n",
    "\n",
    "final_audio +=  silence + chime + silence # 1ç•ª\n",
    "# ğŸ“œ **JSONã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ **\n",
    "json_data.append({\n",
    "    \"index\": 3,\n",
    "    \"original_text\": \"chime\",\n",
    "    \"translated_text\": \"chime\",\n",
    "    \"end_time\": len(final_audio) / 1000,  # ç§’ã«å¤‰æ›\n",
    "    \"type\":\"bridge\",\n",
    "    \n",
    "})\n",
    "\n",
    "# ğŸ”„ **å„ãƒ•ãƒ¬ãƒ¼ã‚ºã”ã¨ã«å‡¦ç†**\n",
    "for i, (eng_audio_file,eng_audio_file_2, jap_text) in enumerate(zip(processed_data[\"english_audio\"],processed_data[\"english_audio_2\"], processed_data[\"translated_texts\"])):\n",
    "    # ğŸµ **å…ƒéŸ³å£°**\n",
    "    eng_audio = AudioSegment.from_file(eng_audio_file, format=\"wav\")\n",
    "    eng_audio = eng_audio.fade_in(100).fade_out(100)\n",
    "    eng_audio_2 = AudioSegment.from_file(eng_audio_file_2, format=\"wav\")\n",
    "    \n",
    "    # ğŸ™ **ãšã‚“ã ã‚‚ã‚“éŸ³å£°**\n",
    "    # print(i)\n",
    "    wav_audio_file = f\"phrase_{i+1}_zunda.wav\"\n",
    "        \n",
    "    # å¤‰æ›ã—ãŸ WAV ã‚’èª­ã¿è¾¼ã‚€\n",
    "    jap_audio = AudioSegment.from_wav(wav_audio_file)\n",
    "\n",
    "    # ğŸ”— **å…ƒéŸ³å£° â†’ ãšã‚“ã ã‚‚ã‚“ â†’ å…ƒéŸ³å£°**\n",
    "    final_audio += eng_audio \n",
    "\n",
    "    # ğŸ“œ **JSONã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ **\n",
    "    json_data.append({\n",
    "        \"index\": i + 4,\n",
    "        \"original_text\": lyrics_data[i][\"text\"],\n",
    "        \"translated_text\": \"!!!!!! NONE !!!!!!!\",\n",
    "        \"end_time\": len(final_audio) / 1000,  # ç§’ã«å¤‰æ›\n",
    "        \"type\":\"original\",\n",
    "    })\n",
    "\n",
    "    final_audio +=  eng_audio_2 \n",
    "\n",
    "    # ğŸ“œ **JSONã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ **\n",
    "    json_data.append({\n",
    "        \"index\": i + 4,\n",
    "        \"original_text\": lyrics_data[i][\"text\"],\n",
    "        \"translated_text\": \"!!!!!! NONE2 !!!!!!!\",\n",
    "        \"end_time\": len(final_audio) / 1000,  # ç§’ã«å¤‰æ›\n",
    "        \"type\":\"English\",\n",
    "        \n",
    "    })\n",
    "\n",
    "    final_audio += jap_audio  + eng_audio + chime \n",
    "\n",
    "    # ğŸ“œ **JSONã«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ **\n",
    "    json_data.append({\n",
    "        \"index\": i + 4,\n",
    "        \"original_text\": lyrics_data[i][\"text\"],\n",
    "        \"translated_text\": jap_text,\n",
    "        \"end_time\": len(final_audio) / 1000,  # ç§’ã«å¤‰æ›\n",
    "        \"type\":\"Japanese\",\n",
    "        \n",
    "    })\n",
    "\n",
    "# ğŸ”š **æœ€å¾Œã«ã‚‚ã†ä¸€åº¦ 1ç•ªã®å…ƒéŸ³æºï¼ˆãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆï¼‰**\n",
    "final_audio += silence_2  \n",
    "json_data.append({\n",
    "    \"index\": i+5,\n",
    "    \"original_text\": \"chime_2\",\n",
    "    \"translated_text\": \"chime_verse_2\",\n",
    "    \"end_time\": len(final_audio) / 1000,  # ç§’ã«å¤‰æ›\n",
    "    \"type\":\"bridge\",\n",
    "    \n",
    "})\n",
    "final_audio +=  first_verse.fade_out(3000)\n",
    "json_data.append({\n",
    "    \"index\": i+6,\n",
    "    \"original_text\": \"first_verse_2\",\n",
    "    \"translated_text\": \"first_verse_2\",\n",
    "    \"end_time\": len(final_audio) / 1000,  # ç§’ã«å¤‰æ›\n",
    "    \"type\":\"bridge\",\n",
    "    \n",
    "})\n",
    "\n",
    "\n",
    "# ğŸ’¾ **éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜**\n",
    "final_audio.export(\"final_output.mp3\", format=\"mp3\")\n",
    "print(\"âœ… final_output.mp3 ã‚’ä½œæˆã—ãŸã®ã ï¼ï¼ğŸ”¥\")\n",
    "\n",
    "# ğŸ“œ **JSONãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜**\n",
    "with open(\"final_output.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json_data, f, ensure_ascii=False, indent=4)\n",
    "print(\"âœ… final_output.json ã‚‚ä½œæˆã—ãŸã®ã ï¼ğŸ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c19847-97c1-4662-ba9b-52ae265da3ca",
   "metadata": {
    "papermill": {
     "duration": 0.005766,
     "end_time": "2025-04-14T09:15:06.341520",
     "exception": false,
     "start_time": "2025-04-14T09:15:06.335754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee94ace-63e1-4ba5-9fc8-c85c7dd18f77",
   "metadata": {
    "papermill": {
     "duration": 25.610843,
     "end_time": "2025-04-14T09:15:31.957911",
     "exception": false,
     "start_time": "2025-04-14T09:15:06.347068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¨ Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-mrMPnnyPnpeaeyIDHJktEGA4/user-iKLyH1mSYw9lswsnJFYrPPNQ/img-TQ9SlwSAMSVAqyygQJR6J5BK.png?st=2025-04-14T20%3A02%3A20Z&se=2025-04-14T22%3A02%3A20Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-14T09%3A35%3A55Z&ske=2025-04-15T09%3A35%3A55Z&sks=b&skv=2024-08-04&sig=bgrqHmoigAZigpw2QEA3K5OoFJKC1nXcsW5Zwnkuslk%3D\n",
      "âœ… Image saved as 'song_background_16_9.jpg'\n",
      "âœ… Diluted image saved as 'song_background_diluted.jpg'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Image saved as 'song_background_16_9.png'\n",
      "âœ… Diluted image saved as 'song_background_diluted.png'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openai\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "\n",
    "# Read and clean lyrics from .txt file\n",
    "with open('corrected_lyrics_with_timestamps.txt', 'r', encoding='utf-8') as file:\n",
    "    lyrics_lines = [re.sub(r\"\\[.*?\\]\\s*\", \"\", line).strip() for line in file]\n",
    "lyrics_data = \" \".join(lyrics_lines)\n",
    "\n",
    "# Descriptive prompt for YouTube aspect ratio (16:9)\n",
    "image_prompt = (\n",
    "    f\"Create an abstract, vibrant, artistic landscape-oriented (16:9 aspect ratio) image inspired by these song lyrics: {lyrics_data}. \"\n",
    "    \"The visuals should be vivid, energetic, expressive, joyful, uplifting, and ideal for a music visualization background or YouTube video.\"\n",
    ")\n",
    "\n",
    "# Generate image with DALL-E at landscape aspect ratio\n",
    "response = openai.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=image_prompt,\n",
    "    size=\"1792x1024\",  # YouTube-friendly 16:9 size\n",
    "    quality=\"hd\",\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "# Get image URL\n",
    "image_url = response.data[0].url\n",
    "print(f\"ğŸ¨ Image URL: {image_url}\")\n",
    "\n",
    "# Download and save the image\n",
    "img_response = requests.get(image_url)\n",
    "with open('song_background_16_9.jpg', 'wb') as image_file:\n",
    "    image_file.write(img_response.content)\n",
    "\n",
    "print(\"âœ… Image saved as 'song_background_16_9.jpg'\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the generated image\n",
    "img = cv2.imread('song_background_16_9.jpg')\n",
    "\n",
    "# Apply a gentle Gaussian blur (increase kernel size for stronger blur)\n",
    "# blurred_img = cv2.GaussianBlur(img, (25, 25), 0)\n",
    "\n",
    "# # Darken the image significantly (adjust the alpha lower for darker)\n",
    "# darker_img = cv2.convertScaleAbs(blurred_img, alpha=0.4, beta=-30)\n",
    "\n",
    "# Resize to exactly854x480 (YouTube 16:9)\n",
    "resized_img = cv2.resize(img, (854, 480), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "cv2.imwrite('song_background_diluted.jpg', resized_img)\n",
    "\n",
    "print(\"âœ… Diluted image saved as 'song_background_diluted.jpg'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0164b-31a2-473c-b0e9-e3b444edbb88",
   "metadata": {
    "papermill": {
     "duration": 0.00587,
     "end_time": "2025-04-14T09:15:31.972308",
     "exception": false,
     "start_time": "2025-04-14T09:15:31.966438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25f0530a-f631-411c-bb31-9e21f8344284",
   "metadata": {
    "papermill": {
     "duration": 25.820109,
     "end_time": "2025-04-14T09:15:57.798136",
     "exception": false,
     "start_time": "2025-04-14T09:15:31.978027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¨ Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-mrMPnnyPnpeaeyIDHJktEGA4/user-iKLyH1mSYw9lswsnJFYrPPNQ/img-VXBwUKlv1z9cvRsHR3jQ6HSx.png?st=2025-04-14T20%3A02%3A44Z&se=2025-04-14T22%3A02%3A44Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-04-14T13%3A43%3A14Z&ske=2025-04-15T13%3A43%3A14Z&sks=b&skv=2024-08-04&sig=yv4QpXIV1OAsdiPY%2BYcb3qj4PtsYYyuvkzbapYgDCOM%3D\n",
      "âœ… Image saved as 'song_background_16_9_2.jpg'\n",
      "âœ… Diluted image saved as 'song_background_diluted.jpg'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Image saved as 'song_background_16_9_2.png'\n",
      "âœ… Diluted image saved as 'song_background_diluted.png'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openai\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = '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'\n",
    "\n",
    "\n",
    "# Read and clean lyrics from .txt file\n",
    "with open('corrected_lyrics_with_timestamps.txt', 'r', encoding='utf-8') as file:\n",
    "    lyrics_lines = [re.sub(r\"\\[.*?\\]\\s*\", \"\", line).strip() for line in file]\n",
    "lyrics_data = \" \".join(lyrics_lines)\n",
    "\n",
    "# Descriptive prompt for YouTube aspect ratio (16:9)\n",
    "image_prompt = (\n",
    "    f\"Create an abstract, vibrant, artistic landscape-oriented (16:9 aspect ratio) image inspired by these song lyrics: {lyrics_data}. \"\n",
    "    \"The visuals should be vivid, energetic, expressive, joyful, uplifting, and ideal for a music visualization background or YouTube video.\"\n",
    ")\n",
    "\n",
    "# Generate image with DALL-E at landscape aspect ratio\n",
    "response = openai.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=image_prompt,\n",
    "    size=\"1792x1024\",  # YouTube-friendly 16:9 size\n",
    "    quality=\"hd\",\n",
    "    n=1,\n",
    ")\n",
    "\n",
    "# Get image URL\n",
    "image_url = response.data[0].url\n",
    "print(f\"ğŸ¨ Image URL: {image_url}\")\n",
    "\n",
    "# Download and save the image\n",
    "img_response = requests.get(image_url)\n",
    "with open('song_background_16_9_2.jpg', 'wb') as image_file:\n",
    "    image_file.write(img_response.content)\n",
    "\n",
    "print(\"âœ… Image saved as 'song_background_16_9_2.jpg'\")\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the generated image\n",
    "img = cv2.imread('song_background_16_9_2.jpg')\n",
    "\n",
    "# Apply a gentle Gaussian blur (increase kernel size for stronger blur)\n",
    "# blurred_img = cv2.GaussianBlur(img, (25, 25), 0)\n",
    "\n",
    "# # Darken the image significantly (adjust the alpha lower for darker)\n",
    "# darker_img = cv2.convertScaleAbs(blurred_img, alpha=0.4, beta=-30)\n",
    "\n",
    "# Resize to exactly 854x480 (YouTube 16:9)\n",
    "resized_img = cv2.resize(img, (854, 480), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "cv2.imwrite('song_background_diluted_2.jpg', resized_img)\n",
    "\n",
    "print(\"âœ… Diluted image saved as 'song_background_diluted.jpg'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e78cfe-dbc4-4b43-a725-7fa03b76362d",
   "metadata": {
    "papermill": {
     "duration": 81.162482,
     "end_time": "2025-04-14T09:17:18.969423",
     "exception": false,
     "start_time": "2025-04-14T09:15:57.806941",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Seamless looping waveform animation frames created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 9c33b2f Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/home/ubuntu/miniconda3/envs/whisper_env --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1627813612080/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-libx264 --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1627813612080/_build_env/bin/pkg-config\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "  libpostproc    55.  7.100 / 55.  7.100\n",
      "Input #0, image2, from 'frames/frame_%04d.jpg':\n",
      "  Duration: 00:00:02.00, start: 0.000000, bitrate: N/A\n",
      "    Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 1240x693 [SAR 100:100 DAR 1240:693], 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x595dc3ddabc0] deprecated pixel format used, make sure you did set range correctly\n",
      "[libx264 @ 0x595dc3d91480] using SAR=3459/3461\n",
      "[libx264 @ 0x595dc3d91480] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x595dc3d91480] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x595dc3d91480] 264 - core 161 r3030M 8bd6d28 - H.264/MPEG-4 AVC codec - Copyleft 2003-2020 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'histogram_loop.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 854x480 [SAR 32860:32879 DAR 1643:924], q=-1--1, 60 fps, 15360 tbn, 60 tbc\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.91.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=   74 fps=0.0 q=31.0 size=       0kB time=00:00:00.25 bitrate=   1.5kbits/s speed= 0.5x    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¬ Final chaotic histogram movie saved as 'looped_histogram_movie.mp4'!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  120 fps=0.0 q=-1.0 Lsize=     733kB time=00:00:01.95 bitrate=3077.3kbits/s speed=2.01x    \n",
      "video:730kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.307691%\n",
      "[libx264 @ 0x595dc3d91480] frame I:1     Avg QP:26.86  size: 89852\n",
      "[libx264 @ 0x595dc3d91480] frame P:31    Avg QP:26.78  size: 14334\n",
      "[libx264 @ 0x595dc3d91480] frame B:88    Avg QP:32.52  size:  2420\n",
      "[libx264 @ 0x595dc3d91480] consecutive B-frames:  1.7%  1.7%  0.0% 96.7%\n",
      "[libx264 @ 0x595dc3d91480] mb I  I16..4:  1.5% 42.8% 55.7%\n",
      "[libx264 @ 0x595dc3d91480] mb P  I16..4:  0.1%  1.6%  1.6%  P16..4: 16.2% 14.6% 10.0%  0.0%  0.0%    skip:56.0%\n",
      "[libx264 @ 0x595dc3d91480] mb B  I16..4:  0.0%  0.0%  0.0%  B16..8: 12.9%  6.6%  2.6%  direct: 3.1%  skip:74.7%  L0:40.1% L1:49.7% BI:10.3%\n",
      "[libx264 @ 0x595dc3d91480] 8x8 transform intra:46.3% inter:48.6%\n",
      "[libx264 @ 0x595dc3d91480] coded y,uvDC,uvAC intra: 93.0% 99.8% 98.5% inter: 8.2% 14.8% 12.1%\n",
      "[libx264 @ 0x595dc3d91480] i16 v,h,dc,p: 36% 14%  7% 43%\n",
      "[libx264 @ 0x595dc3d91480] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 14%  9%  6%  7%  6% 10%  7% 12%\n",
      "[libx264 @ 0x595dc3d91480] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 26% 12% 11%  6% 11%  9%  9%  7%  8%\n",
      "[libx264 @ 0x595dc3d91480] i8c dc,h,v,p: 38% 13% 34% 14%\n",
      "[libx264 @ 0x595dc3d91480] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x595dc3d91480] ref P L0: 61.9% 14.9% 14.3%  8.8%\n",
      "[libx264 @ 0x595dc3d91480] ref B L0: 91.0%  6.6%  2.4%\n",
      "[libx264 @ 0x595dc3d91480] ref B L1: 96.3%  3.7%\n",
      "[libx264 @ 0x595dc3d91480] kb/s:2988.54\n",
      "ffmpeg version 9c33b2f Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/home/ubuntu/miniconda3/envs/whisper_env --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1627813612080/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-libx264 --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1627813612080/_build_env/bin/pkg-config\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "  libpostproc    55.  7.100 / 55.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'histogram_loop.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "  Duration: 00:00:02.00, start: 0.000000, bitrate: 3000 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 854x480 [SAR 3459:3461 DAR 492331:276880], 2991 kb/s, SAR 29401:29418 DAR 1045501:587975, 60 fps, 60 tbr, 15360 tbn, 120 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Output #0, mp4, to 'looped_histogram_movie.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 854x480 [SAR 29401:29418 DAR 1045501:587975], q=2-31, 2991 kb/s, 60 fps, 60 tbr, 15360 tbn, 15360 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "frame=  600 fps=0.0 q=-1.0 Lsize=    3659kB time=00:00:09.95 bitrate=3012.9kbits/s speed=2.07e+03x    \n",
      "video:3652kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.217269%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame=  120 fps=0.0 q=-1.0 Lsize=     557kB time=00:00:01.95 bitrate=2338.8kbits/s speed=2.08x    \n",
      "video:555kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.403826%\n",
      "[libx264 @ 0x5f36ecb30f80] frame I:1     Avg QP:25.76  size: 47512\n",
      "[libx264 @ 0x5f36ecb30f80] frame P:30    Avg QP:26.50  size: 10919\n",
      "[libx264 @ 0x5f36ecb30f80] frame B:89    Avg QP:32.05  size:  2158\n",
      "[libx264 @ 0x5f36ecb30f80] consecutive B-frames:  0.8%  0.0%  2.5% 96.7%\n",
      "[libx264 @ 0x5f36ecb30f80] mb I  I16..4:  2.3% 61.1% 36.6%\n",
      "[libx264 @ 0x5f36ecb30f80] mb P  I16..4:  0.1%  4.0%  2.7%  P16..4: 14.5% 14.9%  8.4%  0.0%  0.0%    skip:55.3%\n",
      "[libx264 @ 0x5f36ecb30f80] mb B  I16..4:  0.0%  0.0%  0.1%  B16..8: 15.7%  7.9%  2.1%  direct: 2.0%  skip:72.3%  L0:41.6% L1:49.0% BI: 9.4%\n",
      "[libx264 @ 0x5f36ecb30f80] 8x8 transform intra:58.7% inter:61.4%\n",
      "[libx264 @ 0x5f36ecb30f80] coded y,uvDC,uvAC intra: 90.1% 99.4% 90.3% inter: 7.2% 12.8% 8.8%\n",
      "[libx264 @ 0x5f36ecb30f80] i16 v,h,dc,p: 24% 10%  2% 64%\n",
      "[libx264 @ 0x5f36ecb30f80] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 33% 12%  9%  4%  9%  9%  9%  6%  8%\n",
      "[libx264 @ 0x5f36ecb30f80] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 40% 11% 14%  5%  7%  8%  6%  6%  5%\n",
      "[libx264 @ 0x5f36ecb30f80] i8c dc,h,v,p: 33% 10% 44% 13%\n",
      "[libx264 @ 0x5f36ecb30f80] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x5f36ecb30f80] ref P L0: 62.7% 14.7% 13.1%  9.5%\n",
      "[libx264 @ 0x5f36ecb30f80] ref B L0: 90.0%  7.0%  2.9%\n",
      "[libx264 @ 0x5f36ecb30f80] ref B L1: 96.0%  4.0%\n",
      "[libx264 @ 0x5f36ecb30f80] kb/s:2268.51\n",
      "ffmpeg version 9c33b2f Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 9.3.0 (crosstool-NG 1.24.0.133_b0863d8_dirty)\n",
      "  configuration: --prefix=/home/ubuntu/miniconda3/envs/whisper_env --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1627813612080/_build_env/bin/x86_64-conda-linux-gnu-cc --disable-doc --disable-openssl --enable-avresample --enable-gnutls --enable-gpl --enable-hardcoded-tables --enable-libfreetype --enable-libopenh264 --enable-libx264 --enable-pic --enable-pthreads --enable-shared --enable-static --enable-version3 --enable-zlib --enable-libmp3lame --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1627813612080/_build_env/bin/pkg-config\n",
      "  libavutil      56. 51.100 / 56. 51.100\n",
      "  libavcodec     58. 91.100 / 58. 91.100\n",
      "  libavformat    58. 45.100 / 58. 45.100\n",
      "  libavdevice    58. 10.100 / 58. 10.100\n",
      "  libavfilter     7. 85.100 /  7. 85.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  7.100 /  5.  7.100\n",
      "  libswresample   3.  7.100 /  3.  7.100\n",
      "  libpostproc    55.  7.100 / 55.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'histogram_loop.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "  Duration: 00:00:02.00, start: 0.000000, bitrate: 2280 kb/s\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 854x480 [SAR 3459:3461 DAR 492331:276880], 2271 kb/s, SAR 29401:29418 DAR 1045501:587975, 60 fps, 60 tbr, 15360 tbn, 120 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Output #0, mp4, to 'looped_histogram_movie.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.45.100\n",
      "    Stream #0:0(und): Video: h264 (High) (avc1 / 0x31637661), yuv420p, 854x480 [SAR 29401:29418 DAR 1045501:587975], q=2-31, 2271 kb/s, 60 fps, 60 tbr, 15360 tbn, 15360 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "frame=  600 fps=0.0 q=-1.0 Lsize=    2780kB time=00:00:09.95 bitrate=2289.2kbits/s speed=2.49e+03x    \n",
      "video:2773kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.283752%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.colors import PowerNorm\n",
    "from matplotlib.collections import LineCollection\n",
    "import subprocess\n",
    "\n",
    "\n",
    "os.makedirs(\"frames\", exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "total_frames = 300\n",
    "fps = 60\n",
    "\n",
    "\n",
    "# Load your processed darkened background image\n",
    "background_img = plt.imread('song_background_diluted.jpg')\n",
    "\n",
    "num_histograms = 10\n",
    "bins = 100\n",
    "data_points = 5000\n",
    "total_frames = 120\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate random histograms with first and last being identical\n",
    "random_histograms = np.random.rand(num_histograms - 1, bins) * 5\n",
    "random_histograms = np.vstack([random_histograms, random_histograms[0]])\n",
    "\n",
    "histogram_times = np.linspace(0, total_frames, num_histograms)\n",
    "\n",
    "def interpolate_histograms(random_histograms, frame, total_frames):\n",
    "    interp_func = make_interp_spline(histogram_times, random_histograms, axis=0, k=3)\n",
    "    return interp_func(frame)\n",
    "\n",
    "# Prepare x-axis bins and smooth interpolation\n",
    "x_bins = np.linspace(0, 40 * np.pi, bins)\n",
    "x_smooth = np.linspace(x_bins.min(), x_bins.max(), data_points)\n",
    "\n",
    "# Animation loop\n",
    "for i in range(total_frames):\n",
    "    fig, ax = plt.subplots(figsize=(16, 9), dpi=100)\n",
    "\n",
    "    # Background image\n",
    "    background_height = 5\n",
    "    ax.imshow(background_img, extent=[x_smooth.min(), x_smooth.max(), 0, background_height], aspect='auto')\n",
    "\n",
    "    # Interpolate histogram for current frame\n",
    "    interpolated_hist = interpolate_histograms(random_histograms, i, total_frames)\n",
    "\n",
    "    # Smooth interpolation along x-axis\n",
    "    spline = make_interp_spline(x_bins, interpolated_hist, k=3)\n",
    "    animated_y = spline(x_smooth)\n",
    "\n",
    "    # Normalize waveform to exactly 70% of background height\n",
    "    waveform_max_height = background_height * 0.7\n",
    "    animated_y = animated_y / np.max(animated_y) * waveform_max_height\n",
    "\n",
    "    # Apply steeper color gradient\n",
    "    norm = PowerNorm(gamma=0.5, vmin=animated_y.min(), vmax=animated_y.max())\n",
    "    points = np.array([x_smooth, animated_y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "    lc = LineCollection(segments, cmap='viridis', norm=norm)\n",
    "    lc.set_array(animated_y)\n",
    "    lc.set_linewidth(2)\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    ax.fill_between(x_smooth, animated_y, 0, color='black', alpha=0.3)\n",
    "\n",
    "    ax.set_xlim(x_smooth.min(), x_smooth.max())\n",
    "    ax.set_ylim(0, background_height)\n",
    "    ax.axis('off')\n",
    "\n",
    "    frame_filename = f\"frames/frame_{i:04d}.jpg\"\n",
    "    plt.savefig(frame_filename, bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "print(\"âœ… Seamless looping waveform animation frames created!\")\n",
    "\n",
    "# Generate video from frames\n",
    "def frames_to_video(frames_folder, output_filename, fps=60):\n",
    "    subprocess.run([\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",\n",
    "        \"-framerate\", str(fps),\n",
    "        \"-i\", f\"{frames_folder}/frame_%04d.jpg\",\n",
    "        \"-vf\", \"scale=854:480:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black\",\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-pix_fmt\", \"yuv420p\",\n",
    "        output_filename\n",
    "    ], check=True)\n",
    "\n",
    "# Loop video\n",
    "def loop_video(input_video, output_video, num_loops):\n",
    "    subprocess.run([\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",\n",
    "        \"-stream_loop\", str(num_loops - 1),\n",
    "        \"-i\", input_video,\n",
    "        \"-c\", \"copy\",\n",
    "        output_video\n",
    "    ], check=True)\n",
    "\n",
    "# Example Usage:\n",
    "if __name__ == \"__main__\":\n",
    "    frames_folder = \"frames\"\n",
    "    short_video = \"histogram_loop.mp4\"\n",
    "    final_video = \"looped_histogram_movie.mp4\"\n",
    "    num_loops = 5\n",
    "\n",
    "    frames_to_video(frames_folder, short_video, fps=fps)\n",
    "    loop_video(short_video, final_video, num_loops)\n",
    "\n",
    "    print(f\"ğŸ¬ Final chaotic histogram movie saved as '{final_video}'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd7b102b-9b4c-4f6e-b17d-beae2fc71281",
   "metadata": {
    "papermill": {
     "duration": 3.193488,
     "end_time": "2025-04-14T09:17:22.171803",
     "exception": false,
     "start_time": "2025-04-14T09:17:18.978315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ GPT-Extracted Keywords: ['mud on your face', 'big disgrace', 'we will rock you', 'take on the world someday']\n",
      "âœ… Image saved as output_1.jpg\n",
      "âœ… Image saved as output_2.jpg\n",
      "âœ… Image saved as output_3.jpg\n",
      "âœ… Image saved as output_4.jpg\n",
      "ğŸ‰ All images generated!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Image saved as output_1.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Image saved as output_2.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Image saved as output_3.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Image saved as output_4.png\n",
      "ğŸ‰ All images generated!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import requests\n",
    "import json\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# âœ… Set API Keys\n",
    "OPENAI_API_KEY = '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'\n",
    "PEXELS_API_KEY = \"u8kqiLXhR9cXf5h8kWMDDmjEbfQ4AevXSvD60H6lPH47jdMRMluxPcCF\"\n",
    "\n",
    "# âœ… Initialize APIs\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "PEXELS_API_URL = \"https://api.pexels.com/v1/search\"\n",
    "\n",
    "# âœ… Step 1: Extract Keywords Using GPT\n",
    "def extract_keywords_gpt(text_file, num_keywords=4):\n",
    "    \"\"\"Uses OpenAI GPT to extract relevant keywords (animals, tools, food, objects).\"\"\"\n",
    "    \n",
    "    with open(text_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Extract {num_keywords} important keywords from the following text. \n",
    "    \n",
    "    Text: {text}\n",
    "    \n",
    "    Return the result as a comma-separated list.\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    keywords = response.choices[0].message.content.strip().split(\", \")\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "# âœ… Step 2: Fetch Images from Pexels API\n",
    "def fetch_image(keyword):\n",
    "    \"\"\"Fetch an image URL from Pexels based on the given keyword.\"\"\"\n",
    "    headers = {\"Authorization\": PEXELS_API_KEY}\n",
    "    params = {\"query\": keyword, \"per_page\": 1}\n",
    "\n",
    "    response = requests.get(PEXELS_API_URL, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code == 200 and response.json()[\"photos\"]:\n",
    "        return response.json()[\"photos\"][0][\"src\"][\"large\"]\n",
    "    else:\n",
    "        print(f\"âŒ No image found for: {keyword}\")\n",
    "        return None\n",
    "\n",
    "# âœ… Step 3: Generate Images with Text Overlay\n",
    "def create_image_with_text(image_url, text, output_filename):\n",
    "    \"\"\"Creates an image with a text overlay using a downloaded image or a blank background.\"\"\"\n",
    "    if image_url:\n",
    "        response = requests.get(image_url)\n",
    "        bg = Image.open(BytesIO(response.content)).convert(\"RGBA\")\n",
    "    else:\n",
    "        bg = Image.new(\"RGBA\", (854, 480), (255, 255, 255, 255))  # White background\n",
    "    \n",
    "    bg = bg.resize((854, 480))\n",
    "    draw = ImageDraw.Draw(bg)\n",
    "\n",
    "    font_path = \"/usr/share/fonts/dejavu/DejaVuSans-Bold.ttf\"  # Ensure this font exists\n",
    "    font_large = ImageFont.truetype(font_path, 60)\n",
    "\n",
    "    # # Centered text\n",
    "    # draw.text((640, 360), text, font=font_large, fill=\"black\", anchor=\"mm\")\n",
    "    bg = bg.convert(\"RGB\") \n",
    "    bg.save(output_filename)\n",
    "    print(f\"âœ… Image saved as {output_filename}\")\n",
    "\n",
    "# âœ… Step 4: Run the Full Pipeline\n",
    "keywords = extract_keywords_gpt(\"corrected_lyrics_with_timestamps.txt\")\n",
    "print(f\"ğŸ¯ GPT-Extracted Keywords: {keywords}\")\n",
    "\n",
    "for i, keyword in enumerate(keywords):\n",
    "    image_url = fetch_image(keyword)\n",
    "    create_image_with_text(image_url, f\"Keyword: {keyword}\", f\"output_{i+1}.jpg\")\n",
    "\n",
    "print(\"ğŸ‰ All images generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "103daf1e-9912-4037-8329-14bbf904db80",
   "metadata": {
    "papermill": {
     "duration": 0.518175,
     "end_time": "2025-04-14T09:17:22.699085",
     "exception": false,
     "start_time": "2025-04-14T09:17:22.180910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Styled text box added to output_text_1.jpg\n",
      "âœ… Styled text box added to output_text_2.jpg\n",
      "âœ… Styled text box added to output_text_3.jpg\n",
      "âœ… Styled text box added to output_text_4.jpg\n",
      "ğŸ‰ All images processed successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Styled text box added to output_text_3.png\n",
      "âœ… Styled text box added to output_text_4.png\n",
      "ğŸ‰ All images processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# âœ… Generate a Random Highlight Color\n",
    "highlight_colors = [\n",
    "    (255, 0, 0),  # Red\n",
    "    (0, 158, 0),  # Green\n",
    "    (0, 0, 255),  # Blue\n",
    "    (255, 165, 0),  # Orange\n",
    "    (128, 0, 128)  # Purple\n",
    "]\n",
    "selected_color = random.choice(highlight_colors)\n",
    "\n",
    "# âœ… Function to Add a Properly Centered Text Box\n",
    "def add_styled_textbox(image_path, text_segments, output_path):\n",
    "    \"\"\"Adds a semi-transparent text box with centered, bold, and colored text at the center of an image.\"\"\"\n",
    "    \n",
    "    # Open Image\n",
    "    img = Image.open(image_path).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # âœ… Define Box Colors\n",
    "    base_color = selected_color\n",
    "    fill_color = (255, 255, 255, 180)  # More White + Transparency\n",
    "    border_color = base_color + (255,)  # Solid Border\n",
    "\n",
    "    # âœ… Load Font\n",
    "    font_path = \"../../src/fonts/nicomoji-plus_v2-5.ttf\"  # Ensure the font file exists\n",
    "    font_size = 20\n",
    "    font_size_0 = 40\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    font_0 = ImageFont.truetype(font_path, font_size_0)\n",
    "\n",
    "    # âœ… Calculate Text Size for Box\n",
    "    text_lines = [segment[\"text\"] for segment in text_segments]\n",
    "    text_widths = [draw.textbbox((0, 0), line, font=font)[2] for line in text_lines]\n",
    "    text_heights = [draw.textbbox((0, 0), line, font=font)[3] for line in text_lines]\n",
    "    \n",
    "    max_text_width = max(text_widths)  # Longest line width\n",
    "    total_text_height = sum(text_heights) + len(text_lines) * 10  # Space between lines\n",
    "\n",
    "    # âœ… Define Box Size & Position (Centered)\n",
    "    box_padding = 50\n",
    "    box_padding_h = 15\n",
    "    box_width = max_text_width + box_padding * 2\n",
    "    box_height = total_text_height + box_padding_h * 2\n",
    "    box_x = (img.width - box_width) / 2\n",
    "    box_y = (img.height - box_height) / 2\n",
    "\n",
    "    # âœ… Create Transparent Overlay\n",
    "    overlay = Image.new(\"RGBA\", img.size, (255, 255, 255, 0))\n",
    "    overlay_draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "    # âœ… Draw Semi-Transparent Box\n",
    "    overlay_draw.rectangle(\n",
    "        [box_x, box_y, box_x + box_width, box_y + box_height],\n",
    "        fill=fill_color, outline=border_color, width=6\n",
    "    )\n",
    "\n",
    "    # âœ… Merge Overlay with Image\n",
    "    img = Image.alpha_composite(img, overlay)\n",
    "\n",
    "    # âœ… Draw Centered Text Inside the Box\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    text_x = box_x + box_padding\n",
    "    text_y = box_y + box_padding_h + 70\n",
    "    text_x_0 = box_width / 2 + 40\n",
    "    text_y_0 = box_y +20\n",
    "\n",
    "    draw.text((text_x_0, text_y_0), text_segments[0][\"text\"], font=font_0, fill=text_segments[1][\"color\"])        \n",
    "    text_y += font_size\n",
    "\n",
    "    #ã“ã®å‹•ç”»ã¯ã†pä¸»ã®è‹±èªå‹‰å¼·ç”¨ãªã®ã \n",
    "    draw.text((text_x, text_y), text_segments[1][\"text\"], font=font, fill=text_segments[1][\"color\"])        \n",
    "    text_y += font_size + 10\n",
    "    #èª°ã‚‚ãŒçŸ¥ã‚‹éŸ³æ¥½ã‚’èããªãŒã‚‰ã€\n",
    "    draw.text((text_x, text_y), text_segments[2][\"text\"], font=font, fill=text_segments[2][\"color\"])        \n",
    "    text_y += font_size + 10\n",
    "    #è‹±èªã‚’å­¦ã¹ã‚‹ã‚ˆã†ã«å·¥å¤«ã‚’ã—ã¦ã¿ãŸã®ã \n",
    "    draw.text((text_x, text_y), text_segments[3][\"text\"], font=font, fill=text_segments[3][\"color\"])        \n",
    "    text_y += font_size + 30\n",
    "    #\n",
    "    #è©¦é¨“çš„ã«Pythonã§å…¨è‡ªå‹•ã§ç”Ÿæˆ\n",
    "    draw.text((text_x, text_y), text_segments[4][\"text\"], font=font, fill=text_segments[4][\"color\"])        \n",
    "    text_widths = draw.textbbox((0, 0), text_segments[4][\"text\"], font=font)[2]\n",
    "    text_x += text_widths\n",
    "    #ã•ã‚Œã¦ã„ã‚‹ã®ã ã€‚\n",
    "    draw.text((text_x, text_y), text_segments[5][\"text\"], font=font, fill=text_segments[5][\"color\"])        \n",
    "    text_x = box_x + box_padding\n",
    "    text_y += font_size + 10\n",
    "    #ä¸è‡ªç„¶ãªç‚¹ã‚„é–“é•ã£ã¦ã„ã‚‹ç‚¹ãŒã‚ã£ãŸã‚‰æ•™ãˆã¦ã»ã—ã„ã®ã \n",
    "    draw.text((text_x, text_y), text_segments[6][\"text\"], font=font, fill=text_segments[6][\"color\"])        \n",
    "    text_y += font_size + 30\n",
    "\n",
    "    #éŸ³æºã¯\n",
    "    draw.text((text_x, text_y), text_segments[7][\"text\"], font=font, fill=text_segments[7][\"color\"])        \n",
    "    text_widths = draw.textbbox((0, 0), text_segments[7][\"text\"], font=font)[2]\n",
    "    text_x += text_widths\n",
    "    #è‘—ä½œæ¨©ãƒ•ãƒªãƒ¼\n",
    "    draw.text((text_x, text_y), text_segments[8][\"text\"], font=font, fill=text_segments[8][\"color\"])        \n",
    "    text_widths = draw.textbbox((0, 0), text_segments[8][\"text\"], font=font)[2]\n",
    "    text_x +=  text_widths\n",
    "    #ã®ã‚‚ã®ã‚’ç”¨ã„ã¦ã„ã‚‹ã®ã ã€‚\n",
    "    draw.text((text_x, text_y), text_segments[9][\"text\"], font=font, fill=text_segments[9][\"color\"])        \n",
    "    text_x = box_x + box_padding\n",
    "    text_y += font_size + 10\n",
    "    #æ°—ã«ãªã‚‹æ–¹ã¯ãƒ–ãƒ©ã‚¦ã‚¶ãƒãƒƒã‚¯ãŒæ¨å¥¨ã•ã‚Œã‚‹ã®ã ã€‚\n",
    "    draw.text((text_x, text_y), text_segments[10][\"text\"], font=font, fill=text_segments[10][\"color\"])        \n",
    "    text_y += font_size + 30\n",
    "\n",
    "\n",
    "    #ä»¥ä¸Šã‚’è¸ã¾ãˆã¦ã€\n",
    "    draw.text((text_x, text_y), text_segments[11][\"text\"], font=font, fill=text_segments[11][\"color\"])        \n",
    "    text_widths = draw.textbbox((0, 0), text_segments[12][\"text\"], font=font)[2]\n",
    "    text_x += text_widths\n",
    "    #ä¸€ç·’ã«æ¥½ã—ã¿ãªãŒã‚‰\n",
    "    draw.text((text_x, text_y), text_segments[12][\"text\"], font=font, fill=text_segments[12][\"color\"])        \n",
    "    text_widths = draw.textbbox((0, 0), text_segments[12][\"text\"], font=font)[2]\n",
    "    text_x += text_widths\n",
    "    #å‹‰å¼·ã—ã‚ˆã†ãªã®ã ï¼\n",
    "    draw.text((text_x, text_y), text_segments[13][\"text\"], font=font, fill=text_segments[13][\"color\"])        \n",
    "\n",
    "    # âœ… Save the Modified Image\n",
    "    img.convert(\"RGB\").save(output_path)\n",
    "    print(f\"âœ… Styled text box added to {output_path}\")\n",
    "\n",
    "    \n",
    "# âœ… Example Usage\n",
    "image_path = \"output_1.jpg\"  # Replace with your actual image\n",
    "output_path = \"output_text_1.jpg\"\n",
    "\n",
    "# âœ… Define Styled Text Segments\n",
    "text_segments = [\n",
    "    {\"text\": \"~ãŠã“ã¨ã‚ã‚Š~ \", \"color\": \"black\"},\n",
    "    {\"text\": \"ã“ã®å‹•ç”»ã¯ã†pä¸»ã®è‹±èªå‹‰å¼·ç”¨ãªã®ã ã€‚ \", \"color\": \"black\"},\n",
    "    {\"text\": \"èª°ã‚‚ãŒçŸ¥ã‚‹æ´‹æ¥½ã‚’èããªãŒã‚‰ã€\", \"color\": selected_color},\n",
    "    {\"text\": \"è‹±èªã‚’å­¦ã¹ã‚‹ã‚ˆã†ã«å·¥å¤«ã‚’ã—ã¦ã¿ãŸã®ã ã€‚\", \"color\": \"black\"},\n",
    "\n",
    "    {\"text\": \"è©¦é¨“çš„ã«æ©Ÿæ¢°å­¦ç¿’ã‚’ä½¿ã„å…¨è‡ªå‹•ã§å‹•ç”»ã‚’ç”Ÿæˆ\", \"color\": selected_color},\n",
    "    {\"text\": \"ã—ã¦ã„ã‚‹ã®ã§ã€\", \"color\": \"black\"},\n",
    "    {\"text\": \"ä¸è‡ªç„¶ãªç‚¹ã‚„é–“é•ã£ã¦ã„ã‚‹ç‚¹ãŒã‚ã‚Œã°æ•™ãˆã¦ã»ã—ã„ã®ã ã€‚\", \"color\": \"black\"},\n",
    "    \n",
    "    {\"text\": \"éŸ³æºã¯ã€\", \"color\": \"black\"},\n",
    "    {\"text\": \"è‘—ä½œæ¨©ãƒ•ãƒªãƒ¼\", \"color\": selected_color},\n",
    "    {\"text\": \"ã®ã‚‚ã®ã‚’ç”¨ã„ã¦ã„ã‚‹ã®ã ã€‚\", \"color\": \"black\"},\n",
    "    {\"text\": \"æ°—ã«ãªã‚‹æ–¹ã¯ãƒ–ãƒ©ã‚¦ã‚¶ãƒãƒƒã‚¯ãŒæ¨å¥¨ã•ã‚Œã‚‹ã®ã ã€‚\", \"color\": \"black\"},\n",
    "    \n",
    "    {\"text\": \"ä»¥ä¸Šã‚’è¸ã¾ãˆã¦ã€\", \"color\": \"black\"},\n",
    "    {\"text\": \"ä¸€ç·’ã«æ¥½ã—ã¿ãªãŒã‚‰\", \"color\": selected_color},\n",
    "    {\"text\": \"å‹‰å¼·ã—ã‚ˆã†ãªã®ã ï¼\", \"color\": \"black\"},\n",
    "]\n",
    "\n",
    "\n",
    "# âœ… Run the Function\n",
    "add_styled_textbox(image_path, text_segments, output_path)\n",
    "\n",
    "\n",
    "# âœ… Function to Add a Properly Centered & Left-Aligned Text Box\n",
    "def add_styled_textbox(image_path, text_segments, output_path):\n",
    "    \"\"\"Adds a semi-transparent text box with left-aligned text except for the title, which is centered.\"\"\"\n",
    "\n",
    "    # Open Image\n",
    "    img = Image.open(image_path).convert(\"RGBA\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # âœ… Define Box Colors\n",
    "    fill_color = (255, 255, 255, 200)  # More White + Semi-Transparency\n",
    "    border_color = selected_color + (255,)  # Solid Border\n",
    "\n",
    "    # âœ… Load Font\n",
    "    font_path = \"../../src/fonts/nicomoji-plus_v2-5.ttf\"  # Ensure the font file exists\n",
    "    font_size = 70\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "    \n",
    "\n",
    "    # âœ… Calculate Text Size for Box\n",
    "    text_lines = [segment[\"text\"] for segment in text_segments]\n",
    "    text_widths = [draw.textbbox((0, 0), line, font=font)[2] for line in text_lines]\n",
    "    text_heights = [draw.textbbox((0, 0), line, font=font)[3] for line in text_lines]\n",
    "\n",
    "    max_text_width = max(text_widths)  # Longest line width\n",
    "    total_text_height = sum(text_heights) + len(text_lines) * 5  # **Reduced Line Spacing**\n",
    "\n",
    "    # âœ… Define Box Size & Position (Centered Box)\n",
    "    box_padding = 25\n",
    "    box_width = max_text_width + box_padding * 2\n",
    "    box_height = total_text_height + box_padding * 2\n",
    "    box_x = (img.width - box_width) / 2\n",
    "    box_y = (img.height - box_height) / 2\n",
    "\n",
    "    # âœ… Create Transparent Overlay\n",
    "    overlay = Image.new(\"RGBA\", img.size, (255, 255, 255, 0))\n",
    "    overlay_draw = ImageDraw.Draw(overlay)\n",
    "\n",
    "    # âœ… Draw Semi-Transparent Box\n",
    "    overlay_draw.rectangle(\n",
    "        [box_x, box_y, box_x + box_width, box_y + box_height],\n",
    "        fill=fill_color, outline=border_color, width=6\n",
    "    )\n",
    "\n",
    "    # âœ… Merge Overlay with Image\n",
    "    img = Image.alpha_composite(img, overlay)\n",
    "\n",
    "    # âœ… Draw Text\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    text_x = box_x + box_padding  # Left-align except for the first line\n",
    "    text_y = box_y + box_padding\n",
    "\n",
    "    for i, segment in enumerate(text_segments):\n",
    "        if i == 0:  # Center-align the title\n",
    "            text_w = draw.textbbox((0, 0), segment[\"text\"], font=font)[2]\n",
    "            centered_x = box_x + (box_width - text_w) / 2\n",
    "            draw.text((centered_x, text_y), segment[\"text\"], font=font, fill=segment[\"color\"])\n",
    "        else:  # Left-align the rest\n",
    "            draw.text((text_x, text_y), segment[\"text\"], font=font, fill=segment[\"color\"])\n",
    "\n",
    "        text_y += font_size + 5  # Reduced line spacing\n",
    "\n",
    "    # âœ… Save the Modified Image\n",
    "    img.convert(\"RGB\").save(output_path)\n",
    "    print(f\"âœ… Styled text box added to {output_path}\")\n",
    "\n",
    "# âœ… Apply Text Boxes to Images\n",
    "image_paths = [\"output_2.jpg\", \"output_3.jpg\", \"output_4.jpg\"]  # Replace with actual file names\n",
    "texts = [{\"text\": \"ãƒ•ãƒ¬ãƒ¼ã‚ºã”ã¨ã®ç¿»è¨³ãªã®ã ï¼\", \"color\": \"black\"} ,{\"text\": \"æ”¹ã‚ã¦æ›²ã‚’èã„ã¦ã¿ã‚‹ã®ã ï¼\", \"color\": \"black\"}  ,{\"text\": \"ã”è¦–è´ã‚ã‚ŠãŒã¨ã†ãªã®ã ï¼\", \"color\": \"black\"}  ]  # Replace with actual extracted words\n",
    "output_paths = [ \"output_text_2.jpg\", \"output_text_3.jpg\", \"output_text_4.jpg\"]\n",
    "\n",
    "for img, txt, out in zip(image_paths, texts, output_paths):\n",
    "    add_styled_textbox(img, [txt], out)  # Pass text as a list\n",
    "\n",
    "\n",
    "print(\"ğŸ‰ All images processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bac703df-093b-4946-a561-0a4c84d6290d",
   "metadata": {
    "papermill": {
     "duration": 0.734124,
     "end_time": "2025-04-14T09:17:23.442543",
     "exception": false,
     "start_time": "2025-04-14T09:17:22.708419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_0.jpg\n",
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_1.jpg\n",
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_2.jpg\n",
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_3.jpg\n",
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_4.jpg\n",
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_5.jpg\n",
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_6.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_2.png\n",
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_3.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_4.png\n",
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_5.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… PNG with Zundamon & Methane-chan created: zunda_methane_output_6.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# âœ… Function to randomly select an image from a given folder\n",
    "def get_random_image(folder_path):\n",
    "    images = [f for f in os.listdir(folder_path) if f.endswith(\".png\")]\n",
    "    if not images:\n",
    "        raise FileNotFoundError(f\"No PNG images found in {folder_path}\")\n",
    "    return os.path.join(folder_path, random.choice(images))\n",
    "\n",
    "folders = [[\"../../src/zunda/No_mike/\", \"../../src/methane/No_mike/\"],\n",
    "                   [\"../../src/zunda/No_mike/\", \"../../src/methane/No_mike/\"],\n",
    "                   [\"../../src/zunda/Close_eyes/\", \"../../src/methane/Close_eyes/\"],\n",
    "                   [\"../../src/zunda/mike/\", \"../../src/methane/mike/\"],\n",
    "                   [\"../../src/zunda/No_mike/\", \"../../src/methane/No_mike/\"],\n",
    "                   [\"../../src/zunda/Close_eyes/\", \"../../src/methane/Close_eyes/\"],\n",
    "                   [\"../../src/zunda/No_mike/\", \"../../src/methane/No_mike/\"]\n",
    "                  ]\n",
    "\n",
    "for i in np.arange(0,len(folders),1):\n",
    "    # âœ… Define paths\n",
    "    zundamon_folder = folders[i][0]\n",
    "    methane_folder = folders[i][1]\n",
    "    # âœ… Get random images\n",
    "    zundamon_path = get_random_image(zundamon_folder)\n",
    "    methane_path = get_random_image(methane_folder)\n",
    "    \n",
    "    # âœ… Load Images\n",
    "    zundamon = Image.open(zundamon_path).convert(\"RGBA\")\n",
    "    methane = Image.open(methane_path).convert(\"RGBA\")\n",
    "    \n",
    "    # âœ… Define Canvas Size (854x480 or match a base image)\n",
    "    canvas_size = (854, 480)\n",
    "    canvas = Image.new(\"RGBA\", canvas_size, (255, 255, 255, 0))  # Transparent background\n",
    "    \n",
    "    # âœ… Resize Zundamon & Methane-chan (Optional)\n",
    "    ratio = 0.15\n",
    "    width = int(round(1082*ratio,0))\n",
    "    height = int(round(1650*ratio,0))\n",
    "    zundamon = zundamon.resize((width, height))  # Adjust if needed\n",
    "    methane = methane.resize((width, height))\n",
    "    \n",
    "    # âœ… Define Positions\n",
    "    zundamon_pos = (canvas_size[0] - zundamon.width - 20, canvas_size[1] - zundamon.height + 80)  # Bottom-right\n",
    "    methane_pos = (20, canvas_size[1] - methane.height + 80)  # Bottom-left\n",
    "    \n",
    "    # âœ… Paste Images onto Canvas\n",
    "    canvas.paste(zundamon, zundamon_pos, zundamon)  # Keep transparency\n",
    "    canvas.paste(methane, methane_pos, methane)\n",
    "    \n",
    "    # âœ… Save the Final Image\n",
    "    output_path = \"zunda_methane_output_{}.jpg\".format(i)\n",
    "    canvas.save(output_path, format=\"PNG\")\n",
    "    \n",
    "    print(f\"âœ… PNG with Zundamon & Methane-chan created: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff9d4e3a-8eb2-40a8-97d9-97da9b85a72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:17:23.460182Z",
     "iopub.status.busy": "2025-04-14T09:17:23.459653Z",
     "iopub.status.idle": "2025-04-14T09:17:23.500702Z",
     "shell.execute_reply": "2025-04-14T09:17:23.500178Z"
    },
    "papermill": {
     "duration": 0.049542,
     "end_time": "2025-04-14T09:17:23.501561",
     "exception": false,
     "start_time": "2025-04-14T09:17:23.452019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Japanese Subtitles: ['é¡”ã«æ³¥ã‚’å¡—ã‚‰ã‚Œã¦ã€å¤§æ¥ã‚’ã‹ã„ã¦ã‚‹ã•ã€‚\\\\Nç¼¶è¹´ã‚Šã—ã¦ã°ã‹ã‚Šã§ã€ã‚ã¡ã“ã¡ã«æ•£ã‚‰ã°\\\\Nã£ã¦ã€æ­Œã£ã¦ã„ã‚‹ã‚“ã ã€‚', 'ç§ãŸã¡ã¯ã€ç§ãŸã¡ã¯ã€ã‚ãªãŸã‚’æºã•ã¶ã‚‹\\\\Nã®ã ', 'å›ã¯è‹¥è€…ã§ã€ç¡¬ã„ç”·ã€é€šã‚Šã§å«ã‚“ã§ã„ã‚‹\\\\Nã€ã„ã¤ã‹ã“ã®ä¸–ç•Œã‚’æ‰‹ã«å…¥ã‚Œã‚‹ã‚“ã ', 'å›ã®é¡”ã«ã¯è¡€ãŒã¤ã„ã¦ã„ã¦ã€å¤§ããªæ¥ã•\\\\Nã‚‰ã—ã€å›ã®æ——ã‚’ã‚ã¡ã“ã¡ã§æŒ¯ã‚Šå›ã—ã¦ã„\\\\Nã‚‹ã®ã ã€‚', 'ç§ãŸã¡ã¯ã€ç§ãŸã¡ã¯ã€ã‚ãªãŸã‚’æºã•ã¶ã‚‹\\\\Nã®ã ']\n",
      "Processed English Subtitles: ['You got mud on your face, you\\\\Nbig disgrace, kicking your can\\\\Nall over the place, singing', 'We will, we will rock you', \"You're a young man, hard man,\\\\Nshouting in the street, gonna\\\\Ntake on the world someday\", 'You got blood on your face,\\\\Nyou big disgrace, waving your\\\\Nbanner all over the place', 'We will, we will rock you']\n",
      "âœ… Successfully created subtitles: lyrics.ass\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import re\n",
    "import textwrap\n",
    "import ast  # To safely convert string representation of a list into a real list\n",
    "\n",
    "\n",
    "# Load JSON file\n",
    "with open(\"final_output.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    json_data = json.load(f)\n",
    "with open(\"formatted_lyrics.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    first_json_data = json.load(f)\n",
    "client = openai.OpenAI(api_key=\"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\")\n",
    "\n",
    "\n",
    "\n",
    "# Start ASS subtitle file\n",
    "# Start ASS subtitle file\n",
    "ass_lines = [\n",
    "    \"[Script Info]\",\n",
    "    \"Title: Lyrics\",\n",
    "    \"ScriptType: v4.00+\",\n",
    "    \"\",\n",
    "    \"[V4+ Styles]\",\n",
    "    \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, \"\n",
    "    \"Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, \"\n",
    "    \"Alignment, MarginL, MarginR, MarginV, Encoding\",\n",
    "    \"Style: English_1,Valty DEMO,20,&H00FFFFFF,&H00000000,&H00000000,&H00000000,1,0,0,0,100,100,0,0,1,3,1,5,10,10,280,1\",\n",
    "    \"Style: English_2,Valty DEMO,20,&H00FFFFFF,&H00000000,&H00FF66CC,&H00000000,1,0,0,0,100,100,0,0,1,3,1,5,10,10,280,1\",\n",
    "    \"Style: Japanese,NicoMoji+v2,16,&H00FFFFFF,&H00000000,&H0066FF66,&H00000000,1,0,0,0,100,100,0,0,1,3,1,5,10,10,200,1\",\n",
    "    \"\",\n",
    "    \"[Events]\",\n",
    "    \"Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\"\n",
    "]\n",
    "# Function to convert seconds to ASS timestamp\n",
    "def ass_timestamp(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    ms = int((seconds - int(seconds)) * 100)  # FFmpeg uses centiseconds\n",
    "    return f\"{h:01}:{m:02}:{s:02}.{ms:02}\"\n",
    "\n",
    "\n",
    "def split_text_Eng(text, max_length_Eng=30):\n",
    "    # ğŸ‡ºğŸ‡¸ English: Break at natural word boundaries (spaces)\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    line = \"\"\n",
    "\n",
    "    for word in words:\n",
    "        if len(line) + len(word) + 1 <= max_length_Eng:\n",
    "            line += \" \" + word if line else word\n",
    "        else:\n",
    "            lines.append(line)\n",
    "            line = word\n",
    "        \n",
    "    if line:\n",
    "        lines.append(line)\n",
    "\n",
    "    return \"\\\\N\".join(lines)  # Use `\\N` for ASS format\n",
    "\n",
    "\n",
    "# def split_text_Jap(text,max_length_Jap=15):\n",
    "#     response = client.chat.completions.create(\n",
    "#         model=\"gpt-4\",\n",
    "#         messages=[\n",
    "#             {\"role\": \"system\", \"content\": \"You are a lyrics processing assistant.\"},\n",
    "#             {\"role\": \"user\", \"content\": f\"\"\"The following list contains a corrected song lyrics in each row:\n",
    "#     ---\n",
    "#     {text}\n",
    "#     ---\n",
    "#     Your task:\n",
    "#     - Connect sentences from each raws of the input list and make a plane text, and sentences from each raws are connected by \"-\" .\n",
    "#     - Insert \"+\" between words in each sentences when each sentences has over about {max_length_Jap} characters to make smooth line break.\n",
    "#     - Remove the quotation mark \n",
    "#     - Return the processed lyrics as **a text**.\n",
    "#     \"\"\"}\n",
    "#         ]\n",
    "#     )\n",
    "\n",
    "#     # ğŸ“œ Extract GPT-4's response\n",
    "#     gpt_response = response.choices[0].message.content.strip()\n",
    "    \n",
    "#     # Remove English letters, digits, and common symbols\n",
    "#     clean_text = re.sub(r'[A-Za-z0-9\\s!\"#$%&\\'()*,./:;<=>?@\\[\\\\\\]^_`{|}~]+', '',gpt_response)\n",
    "#     # âœ… Convert into a clean list\n",
    "#     lyrics_sections = clean_text.split(\"-\")  # Separate by \"-\"\n",
    " \n",
    "#     print(\"GPT-4 Raw Response:\", lyrics_sections)  # Debugging Output\n",
    "#     return lyrics_sections\n",
    "\n",
    "def break_japanese_text(text, max_chars=18):\n",
    "    return '\\\\N'.join([text[i:i+max_chars] for i in range(0, len(text), max_chars)])\n",
    "\n",
    "\n",
    "\n",
    "# ğŸ“ Process lyrics\n",
    "subtitle_text_prep_Eng = []\n",
    "subtitle_text_prep_Jap = []\n",
    "subtitle_text_Eng = []\n",
    "subtitle_text_Jap = []\n",
    "\n",
    "for entry in json_data:\n",
    "    if entry[\"type\"] == \"Japanese\":\n",
    "        subtitle_text_prep_Eng.append(entry[\"original_text\"])\n",
    "        subtitle_text_prep_Jap.append(entry[\"translated_text\"])\n",
    "# ğŸ¶ Split text\n",
    "\n",
    "# subtitle_text_Jap=split_text_Jap(subtitle_text_prep_Jap)\n",
    "\n",
    "for i in np.arange(0,len(subtitle_text_prep_Eng),1):\n",
    "    subtitle_text_Eng.append(split_text_Eng(subtitle_text_prep_Eng[i]))\n",
    "    subtitle_text_Jap.append(break_japanese_text(subtitle_text_prep_Jap[i]))\n",
    "\n",
    "# ğŸ›  Debugging Output\n",
    "print(\"Processed Japanese Subtitles:\", subtitle_text_Jap)\n",
    "print(\"Processed English Subtitles:\", subtitle_text_Eng)\n",
    "\n",
    "\n",
    "\n",
    "silence_1_duration = json_data[1][\"end_time\"]  # Duration of Notion image before waveform starts\n",
    "silence_3_duration = json_data[-2][\"end_time\"]  # Total duration of the final video\n",
    "fade_duration = 500 \n",
    "\n",
    "j=0\n",
    "previous_time = 0  # Track previous subtitle's time\n",
    "for entry in first_json_data:\n",
    "    start_time = silence_1_duration + entry[\"start\"]\n",
    "    end_time = silence_1_duration + entry[\"end\"]\n",
    "    subtitle_text = subtitle_text_Eng[j]\n",
    "    style = \"English_1\"\n",
    "    ass_lines.append(\n",
    "        f\"Dialogue: 0,{ass_timestamp(start_time+0.01)},{ass_timestamp(end_time)},{style},,0,0,0,,{{\\fad({fade_duration},{fade_duration})}}{subtitle_text}\"\n",
    "    )\n",
    "    j += 1 \n",
    "    \n",
    "    # print(\"english:\",entry[\"text\"])\n",
    "    \n",
    "previous_time = 0  # Track previous subtitle's time\n",
    "j = 0\n",
    "# Convert each lyric entry to ASS format\n",
    "for entry in json_data:\n",
    "    if entry[\"type\"] == \"bridge\":\n",
    "        # print(\"skip:\",entry[\"translated_text\"])\n",
    "        previous_entry = entry[\"end_time\"]    \n",
    "        continue  # Skip empty lines and chimes\n",
    "\n",
    "    if entry[\"type\"] == \"original\":\n",
    "        start_time = previous_entry\n",
    "        end_time = entry[\"end_time\"]\n",
    "        subtitle_text = subtitle_text_Eng[j]\n",
    "        style = \"English_1\"\n",
    "        # print(\"english:\",entry[\"original_text\"])\n",
    "        ass_lines.append(\n",
    "        f\"Dialogue: 0,{ass_timestamp(start_time)},{ass_timestamp(end_time)},{style},,0,0,0,,{{\\fad({fade_duration},{fade_duration})}}{subtitle_text}\"\n",
    "        )\n",
    "\n",
    "\n",
    "    if entry[\"type\"] == \"English\":\n",
    "        start_time = previous_entry\n",
    "        end_time = entry[\"end_time\"]\n",
    "        subtitle_text = subtitle_text_Eng[j]\n",
    "        style = \"English_2\"\n",
    "        # print(\"english:\",entry[\"original_text\"])\n",
    "        ass_lines.append(\n",
    "        f\"Dialogue: 0,{ass_timestamp(start_time)},{ass_timestamp(end_time)},{style},,0,0,0,,{{\\fad({fade_duration},{fade_duration})}}{subtitle_text}\"\n",
    "        )\n",
    "\n",
    "    \n",
    "    if entry[\"type\"] == \"Japanese\":\n",
    "        start_time = previous_entry \n",
    "        end_time = entry[\"end_time\"]\n",
    "        subtitle_text_1 =  subtitle_text_Eng[j]\n",
    "        subtitle_text_2 = subtitle_text_Jap[j].replace(\"+\", r\"\\N\")\n",
    "        style_1 = \"English_2\"\n",
    "        style_2 = \"Japanese\"\n",
    "        # print(\"Japanese:\",entry[\"translated_text\"])\n",
    "        ass_lines.append(\n",
    "        f\"Dialogue: 0,{ass_timestamp(start_time)},{ass_timestamp(end_time)},{style_1},,0,0,0,,{{\\fad({fade_duration},{fade_duration})}}{subtitle_text_1}\"\n",
    "        )\n",
    "        ass_lines.append(\n",
    "        f\"Dialogue: 0,{ass_timestamp(start_time)},{ass_timestamp(end_time)},{style_2},,0,0,0,,{{\\fad({fade_duration},{fade_duration})}}{subtitle_text_2}\"\n",
    "        )\n",
    "        j += 1 \n",
    "\n",
    "    previous_entry = entry[\"end_time\"]\n",
    "\n",
    "\n",
    "j=0\n",
    "previous_time = 0  # Track previous subtitle's time\n",
    "for entry in first_json_data:\n",
    "    start_time = silence_3_duration + entry[\"start\"]\n",
    "    end_time = silence_3_duration + entry[\"end\"]\n",
    "    subtitle_text = subtitle_text_Eng[j]\n",
    "    style = \"English_1\"\n",
    "    ass_lines.append(\n",
    "        f\"Dialogue: 0,{ass_timestamp(start_time+0.01)},{ass_timestamp(end_time)},{style},,0,0,0,,{{\\fad({fade_duration},{fade_duration})}}{subtitle_text}\"\n",
    "    )\n",
    "    j += 1 \n",
    "\n",
    "\n",
    "# Save as an ASS file\n",
    "with open(\"lyrics.ass\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(ass_lines))\n",
    "\n",
    "print(\"âœ… Successfully created subtitles: lyrics.ass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ac0ba-1dfe-4c3c-9afe-2c2dc079b16a",
   "metadata": {
    "papermill": {
     "duration": 0.0066,
     "end_time": "2025-04-14T09:17:23.515121",
     "exception": false,
     "start_time": "2025-04-14T09:17:23.508521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c590b91a-9c53-4338-9be1-a2bc3322fc96",
   "metadata": {
    "papermill": {
     "duration": 0.218761,
     "end_time": "2025-04-14T09:17:23.740638",
     "exception": false,
     "start_time": "2025-04-14T09:17:23.521877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Video processing complete: final_video.mp4\n"
     ]
    }
   ],
   "source": [
    "#### import json\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import json\n",
    "\n",
    "# **æ—¢å­˜ã® `final_video.mp4` ã‚’å‰Šé™¤**\n",
    "if os.path.exists(\"final_video.mp4\"):\n",
    "    os.remove(\"final_video.mp4\")\n",
    "    print(\"ğŸ—‘ï¸ Removed existing final_video.mp4\")\n",
    "\n",
    "with open(\"final_output.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    json_data = json.load(f)\n",
    "with open(\"processed_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    processed_data = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "chime_file = \"../../src/sounds/Bell_Accent06-1(Dry).mp3\"  # æ³¨æ„æ›¸ãã®å‰ã®ãƒãƒ£ã‚¤ãƒ éŸ³\n",
    "# ğŸ”” **ãƒãƒ£ã‚¤ãƒ ã¨é–“ï¼ˆæ•°ç§’ï¼‰**\n",
    "chime = AudioSegment.from_file(chime_file, format=\"mp3\")\n",
    "chime_time = len(chime) / 1000\n",
    "silence = AudioSegment.silent(duration=1000)\n",
    "silence_time = len(silence)/1000\n",
    "\n",
    "\n",
    "notion_duration = json_data[1][\"end_time\"]  # Duration of Notion image before waveform starts\n",
    "silence_1_duration = json_data[1][\"end_time\"]  # Duration of Notion image before waveform starts\n",
    "video_1_duration = json_data[2][\"end_time\"]  # Duration of Notion image before waveform starts\n",
    "silence_2_duration = json_data[3][\"end_time\"]  # Duration of Notion image before waveform starts\n",
    "trans_i_duration = []\n",
    "methane_duration = []\n",
    "zunda_duration = []\n",
    "for i in np.arange(0,len(processed_data[\"english_audio\"]),1):\n",
    "    trans_i_duration.append(json_data[4+3*i][\"end_time\"])\n",
    "    methane_duration.append(json_data[4+3*i+1][\"end_time\"])\n",
    "    zunda_duration.append(json_data[4+3*i+2][\"end_time\"])\n",
    "silence_3_duration = json_data[-2][\"end_time\"]  # Total duration of the final video\n",
    "video_2_duration = json_data[-1][\"end_time\"]  # Duration of Notion image before waveform starts\n",
    "fade_duration = 0.5  # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ»ã‚¢ã‚¦ãƒˆã®é•·ã•ï¼ˆç§’ï¼‰\n",
    "black_duration = 1\n",
    "desired_duration_song_bg = silence_3_duration- silence_2_duration\n",
    "desired_duration_trans = silence_2_duration - video_1_duration\n",
    "desired_duration_second = silence_3_duration - trans_i_duration[-1]\n",
    "last_fadeout_duration = 3\n",
    "\n",
    "# FFmpeg command with improved logic\n",
    "ffmpeg_cmd = [\n",
    "    \"/usr/bin/ffmpeg\",\n",
    "    # \"-hwaccel\", \"cuda\",  # ğŸš€ Enable GPU Acceleration\n",
    "    # \"-hwaccel_output_format\", \"cuda\",\n",
    "\n",
    "    # **å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«**\n",
    "    \"-loop\", \"1\", \"-t\", str(notion_duration), \"-i\", \"output_text_1.jpg\",\n",
    "    \"-stream_loop\", \"-1\", \"-i\", \"looped_histogram_movie.mp4\",\n",
    "    \"-i\", \"../../src/frames/outframe.mp4\",  # **ãƒ•ãƒ¬ãƒ¼ãƒ å‹•ç”» (wave ã®ä¸Šã«é‡ã­ã‚‹)**\n",
    "    # Input images with looping and duration setting\n",
    "    \"-loop\", \"1\", \"-t\", str(desired_duration_song_bg), \"-i\", \"song_background_diluted.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(desired_duration_trans), \"-i\", \"output_text_2.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(desired_duration_second), \"-i\", \"output_text_3.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(last_fadeout_duration), \"-i\", \"output_text_4.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(video_1_duration), \"-i\", \"zunda_methane_output_0.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(video_1_duration), \"-i\", \"zunda_methane_output_1.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(video_1_duration), \"-i\", \"zunda_methane_output_2.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(video_1_duration), \"-i\", \"zunda_methane_output_3.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(video_1_duration), \"-i\", \"zunda_methane_output_4.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(video_1_duration), \"-i\", \"zunda_methane_output_5.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(video_1_duration), \"-i\", \"zunda_methane_output_6.jpg\",\n",
    "    \"-loop\", \"1\", \"-t\", str(desired_duration_song_bg), \"-i\", \"song_background_diluted_2.jpg\",\n",
    "    \"-i\", \"final_output.mp3\",  # **éŸ³å£°**\n",
    "    \n",
    "    # **ãƒ•ã‚£ãƒ«ã‚¿ã®é©ç”¨**\n",
    "    \"-filter_complex\",\n",
    "    ##**Notionç”»åƒã‚’ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ»ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ**\n",
    "    \"color=c=black:s=854x480:d=\" + str(silence_1_duration) +\"[black]; \"   \n",
    "    # \n",
    "    \"[0:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\"\n",
    "    + str(silence_1_duration-( black_duration - fade_duration ))+\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration)+ \n",
    "    \",fade=t=out:st=\" + str(silence_1_duration -black_duration) + \n",
    "    \":d=\" + str(fade_duration)  + \"[notion]; \"  \n",
    "    \"[black][notion]overlay[out_1_0];\"\n",
    "    # \"[black][notion]overlay=enable='gte(t,\"+str( black_duration - fade_duration )+\")'[out_1];\"\n",
    "    \"[7:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\"\n",
    "    + str(silence_1_duration-( black_duration - fade_duration ))+\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration)+ \n",
    "    \",fade=t=out:st=\" + str(silence_1_duration -black_duration) + \n",
    "    \":d=\" + str(fade_duration)  + \"[zunda_0]; \"  \n",
    "    \"[out_1_0][zunda_0]overlay[out_1];\"\n",
    "    \n",
    "    # **æ³¢å½¢å‹•ç”»ã‚’ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ»ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ**\n",
    "    \"color=c=black:s=854x480:d=\"+ str(video_1_duration -silence_1_duration) +\"[black]; \"   \n",
    "    # \n",
    "    \"[1:v]split=2[first_corse_1][first_corse_2];\"\n",
    "    \"[first_corse_1]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\" \n",
    "    + str(video_1_duration - silence_1_duration- (black_duration - fade_duration)) +\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) + \n",
    "    \",fade=t=out:st=\" + str(video_1_duration - silence_1_duration -black_duration) + \n",
    "    \":d=\" + str(fade_duration) + \"[wave]; \"\n",
    "    \"[black][wave]overlay[out_2_0];\"\n",
    "    \n",
    "    \"[8:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\"\n",
    "    + str(video_1_duration - silence_1_duration- (black_duration - fade_duration)) +\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) + \n",
    "    \",fade=t=out:st=\" + str(video_1_duration - silence_1_duration -black_duration) +  \n",
    "    \":d=\" + str(fade_duration)  + \"[zunda_1]; \"  \n",
    "    \"[out_2_0][zunda_1]overlay[out_2];\"\n",
    "\n",
    "    # \"[black][wave]overlay=enable='gte(t,\"+str(black_duration-fade_duration)+\")'[out_2];\"\n",
    "    # # **ãƒ•ãƒ¬ãƒ¼ãƒ å‹•ç”» (`outframe.mp4`) ã‚’ `wave` ã®ä¸Šã«é‡ã­ã‚‹**\n",
    "    # \"[2:v]scale=854:-1,pad=854:480:(ow-iw)/2:(oh-ih)/2,setsar=1[frame]; \"  # **ã‚µã‚¤ã‚ºèª¿æ•´**\n",
    "    # \"[wave][frame]overlay=format=auto:eof_action=pass[wave_frame]; \"  # **waveã®ä¸Šã«ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’é‡ã­ã‚‹**\n",
    "    # **transç”»åƒã‚’ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ»ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ**\n",
    "    \"color=c=black:s=854x480:d=\"+ str(silence_2_duration - video_1_duration) +\"[black]; \"   \n",
    "    #     \n",
    "    \"[4:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\" \n",
    "    + str(silence_2_duration - video_1_duration - (black_duration - fade_duration))+\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) + \n",
    "    \",fade=t=out:st=\" + str(silence_2_duration - video_1_duration - black_duration ) + \n",
    "    \":d=\" + str(fade_duration) + \"[trans]; \"  \n",
    "    \"[black][trans]overlay[out_3_0];\"\n",
    "    # \"[black][trans]overlay=enable='gte(t,\"+str( black_duration - fade_duration )+\")':format=auto[out_3];\"\n",
    "    \"[9:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\"\n",
    "     + str(silence_2_duration - video_1_duration - (black_duration - fade_duration))+\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) + \n",
    "    \",fade=t=out:st=\" + str(silence_2_duration - video_1_duration - black_duration ) + \n",
    "    \":d=\" + str(fade_duration)  + \"[zunda_2]; \"  \n",
    "    \"[out_3_0][zunda_2]overlay[out_3];\"\n",
    "    \n",
    "    # **åŠé€æ˜ã®é»’é•·æ–¹å½¢ (fadeé©ç”¨ãªã—)**\n",
    "    \"color=c=black:s=854x480:d=\"+ str(zunda_duration[-1]- silence_2_duration) +\"[black]; \"   \n",
    "    # \n",
    "    \"color=c=black@0.6:s=1100x600:d=\" + str(zunda_duration[-1]- silence_2_duration - (black_duration -fade_duration)) + \"[overlay_black_raw]; \"\n",
    "    # **ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ»ã‚¢ã‚¦ãƒˆã‚’é©ç”¨**\n",
    "    \"[overlay_black_raw]fade=t=in:st=0:d=\" + str(fade_duration) + \",\"\n",
    "    \"fade=t=out:st=\" + str(zunda_duration[-1]- silence_2_duration -black_duration) + \":d=\" + str(fade_duration) + \"[overlay_black]; \"\n",
    "    \"[overlay_black]drawbox=x=0:y=0:w=iw:h=ih:t=10:color=orange@0.9[rounded_black]; \"\n",
    "    # \"[trans_bg][rounded_black]overlay=(W-w)/2:(H-h)/2:format=auto:eof_action=pass[trans_frame_black]; \"\n",
    "    # **\n",
    "    \"[14:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\" \n",
    "    + str(zunda_duration[-1]- silence_2_duration - (black_duration - fade_duration))+\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) +\n",
    "    \",fade=t=out:st=\" + str(zunda_duration[-1]- silence_2_duration -black_duration ) + \n",
    "    \":d=\" + str(fade_duration) + \"[trans_bg]; \"\n",
    "    \"[trans_bg][rounded_black]overlay=(W-w)/2:(H-h)/2[trans_pic_bg];\"\n",
    "    # \"[trans_bg][trans_frame_black]overlay=(W-w)/2:(H-h)/2[trans_pic_bg];\"\n",
    "    # **\n",
    "    \"[black][trans_pic_bg]overlay[out_4_0];\"\n",
    "    # \"[black][trans_pic_bg]overlay=enable='gte(t,\"+str(black_duration - fade_duration)+\")'[out_4];\"\n",
    "    # \"[black][trans]overlay=enable='gte(t,\"+str( black_duration - fade_duration )+\")':format=auto[out_3];\"\n",
    "    \"[10:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\"\n",
    "    + str(zunda_duration[-1]- silence_2_duration - (black_duration - fade_duration))+\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) +\n",
    "    \",fade=t=out:st=\" + str(zunda_duration[-1]- silence_2_duration -black_duration ) + \n",
    "    \":d=\" + str(fade_duration)  + \"[zunda_3]; \"  \n",
    "    \"[out_4_0][zunda_3]overlay[out_4];\"\n",
    "    \n",
    "    # **transç”»åƒã‚’ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ»ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ**\n",
    "    \"color=c=black:s=854x480:d=\"+ str(silence_3_duration - zunda_duration[-1]) +\"[black]; \"   \n",
    "    # \n",
    "    \"[5:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\" \n",
    "    + str(silence_3_duration - zunda_duration[-1] - (black_duration - fade_duration))+\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) + \n",
    "    \",fade=t=out:st=\" + str(silence_3_duration - zunda_duration[-1] - black_duration) +\n",
    "    \":d=\" + str(fade_duration) + \"[second]; \"  \n",
    "    \"[black][second]overlay[out_5_0];\"\n",
    "    # \"[black][second]overlay=enable='gte(t,\"+str( black_duration - fade_duration )+\")':format=auto[out_5];\"\n",
    "    \n",
    "    \"[11:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\"\n",
    "    + str(silence_3_duration - zunda_duration[-1] - (black_duration - fade_duration))+\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) + \n",
    "    \",fade=t=out:st=\" + str(silence_3_duration - zunda_duration[-1] - black_duration) +\n",
    "    \":d=\" + str(fade_duration)  + \"[zunda_4]; \"  \n",
    "    \"[out_5_0][zunda_4]overlay[out_5];\"\n",
    "    \n",
    "    # **æ³¢å½¢å‹•ç”»ã‚’ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ»ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ**\n",
    "    \"color=c=black:s=854x480:d=\"+ str(video_1_duration -silence_1_duration-fade_duration - last_fadeout_duration) +\"[black]; \"   \n",
    "    # \n",
    "    \"[first_corse_2]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\" \n",
    "    + str(video_1_duration - silence_1_duration- (black_duration - fade_duration)-last_fadeout_duration ) +\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) + \n",
    "    \",fade=t=out:st=\" + str(video_1_duration - silence_1_duration -black_duration-last_fadeout_duration) + \n",
    "    \":d=\" + str(fade_duration) + \"[wave]; \"\n",
    "    \"[black][wave]overlay[out_6_0];\"\n",
    "\n",
    "    \"[12:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\"\n",
    "    + str(video_1_duration - silence_1_duration- (black_duration - fade_duration) -last_fadeout_duration) +\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) +  \n",
    "    \",fade=t=out:st=\" + str(video_1_duration - silence_1_duration -black_duration-last_fadeout_duration) + \n",
    "    \":d=\" + str(fade_duration) + \"[zunda_6]; \"  \n",
    "    \"[out_6_0][zunda_6]overlay[out_6];\"\n",
    "    \n",
    "\n",
    "    # **transç”»åƒã‚’ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ»ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ**\n",
    "    \"color=c=black:s=854x480:d=\"+ str(last_fadeout_duration) +\"[black]; \" \n",
    "    # \n",
    "    \"[6:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\"\n",
    "    + str(last_fadeout_duration - (black_duration - fade_duration))+\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration)  +\"[end]; \"  \n",
    "    \"[black][end]overlay[out_7_0];\"\n",
    "    # \"[black][second]overlay=enable='gte(t,\"+str( black_duration - fade_duration )+\")':format=auto[out_5];\"\n",
    "    \"[13:v]scale=854:-1:force_original_aspect_ratio=decrease,pad=854:480:(ow-iw)/2:(oh-ih)/2:black,setsar=1,trim=start=0:duration=\"\n",
    "    + str(last_fadeout_duration - (black_duration - fade_duration))+\n",
    "    \",fade=t=in:st=0:d=\" + str(fade_duration) + \"[zunda_7]; \"  \n",
    "    \"[out_7_0][zunda_7]overlay[out_7];\"\n",
    "    \n",
    "    # # **é»’èƒŒæ™¯ã®ä¸Šã« Notionç”»åƒã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤*\n",
    "    \"[out_1][out_2][out_3][out_4][out_5]concat=n=5:v=1:a=0[first];\"\n",
    "    \"[first][out_6][out_7]concat=n=3:v=1:a=0[fullvideo];\"\n",
    "\n",
    "    \n",
    "    # **å­—å¹•é©ç”¨**\n",
    "    \"[fullvideo]ass=lyrics.ass[outv]\",  \n",
    "    # \"[fullvideo]null[outv]\",\n",
    "    \n",
    "    # # **å‡ºåŠ›è¨­å®š**\n",
    "    # \"-shortest\",\n",
    "    # \"-map\", \"[outv]\", \"-map\", \"15:a:0\",  \n",
    "    # \"-c:v\", \"h264_nvenc\",\n",
    "    # \"-pix_fmt\", \"yuv420p\",\n",
    "    # \"-c:a\", \"aac\",\n",
    "    # \"-b:a\", \"192k\",\n",
    "    # \"-af\", \"volume=1.0\",  # Ensure audio isn't muted\n",
    "    # \"final_video.mp4\"\n",
    "    # **å‡ºåŠ›è¨­å®š**\n",
    "    \"-shortest\",\n",
    "    \"-r\", \"30\",  # ğŸ‘ˆ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆä¸‹ã’ã‚‹\n",
    "    \"-map\", \"[outv]\", \"-map\", \"15:a:0\",\n",
    "    \"-c:v\", \"libx264\",\n",
    "    \"-preset\", \"fast\",  # ğŸ‘ˆ é«˜é€Ÿãƒ—ãƒªã‚»ãƒƒãƒˆè¿½åŠ \n",
    "    \"-pix_fmt\", \"yuv420p\",\n",
    "    \"-c:a\", \"aac\",\n",
    "    \"-b:a\", \"192k\",\n",
    "    \"-af\", \"volume=1.0\",\n",
    "    \"final_video.mp4\"\n",
    "]\n",
    "\n",
    "\n",
    "ffmpeg_cmd.extend([\"-loglevel\", \"verbose\"])\n",
    "\n",
    "# Run FFmpeg command in Python\n",
    "try:\n",
    "    process = subprocess.run(ffmpeg_cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(\"âœ… Video processing complete: final_video.mp4\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"âŒ FFmpeg Error:\")\n",
    "    print(e.stderr.decode())  # Show FFmpeg error details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "118c406d-b083-4447-adfc-3bbadb6fec5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T09:17:23.758631Z",
     "iopub.status.busy": "2025-04-14T09:17:23.758185Z",
     "iopub.status.idle": "2025-04-14T09:17:23.761257Z",
     "shell.execute_reply": "2025-04-14T09:17:23.760581Z"
    },
    "papermill": {
     "duration": 0.011732,
     "end_time": "2025-04-14T09:17:23.762126",
     "exception": false,
     "start_time": "2025-04-14T09:17:23.750394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Video\n",
    "\n",
    "# video_path = \"final_video.mp4\"  # Ensure this path is correct\n",
    "# Video(video_path, embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e4851-a15b-43f1-a61e-9a7708b12efd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 257.098569,
   "end_time": "2025-04-14T09:17:26.431127",
   "environment_variables": {},
   "exception": null,
   "input_path": "songs_dataset/Queen_We_Will_Rock_You/Music.ipynb",
   "output_path": "songs_dataset/Queen_We_Will_Rock_You/Music_output.ipynb",
   "parameters": {},
   "start_time": "2025-04-14T09:13:09.332558",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
